{
    "brief": "None<br> ",
    "html_url": "https://blog.compass-security.com/2023/10/relaying-ntlm-to-mssql/",
    "text": null,
    "title": "Relaying NTLM to MSSQL"
}
{
    "brief": "None<br> ",
    "html_url": "https://blog.compass-security.com/2023/10/device-code-phishing-compass-tooling/",
    "text": null,
    "title": "Device Code Phishing – Compass Tooling"
}
{
    "brief": "After publishing my blog post about running P4wnP1 on an LTE modem, where I explained how to install Linux and P4wnP1 on an actual LTE modem for sneaky USB attacks, and then trying and failing to do an internal presentation to show it off to folks, I realised that I had not completely documented the process.<br> \nIn the previous post, I also described setting up a Wireguard VPN to an Internet-accessible host, and then using SSH to access the modem over that VPN.<br> \nFurthermore, when the WiFi link was up, and Wireguard was routing over WiFi, I had no problems running the same commands.<br> \nWhat is MTU, though?<br> \nI used this with an ever decreasing packet size to try and figure out what the MTU of my LTE interface was.<br> \nIt was defaulted to something like 1500, but to my surprise, I got all the way down to an ICMP data size of 996 before I was able to successfully get an ICMP response back.<br> \nAfter setting the LTE MTU to 1024, I was able to successfully establish the Wireguard VPN, and SSH connection over LTE, and execute all the commands that were failing previously.<br> \nThis is because the MTU is only effective in a single direction, for packets SENT from the system, and doesn’t affect the size of packets received.<br> \nWireguard works just fine over LTE with an MTU of 1420.<br> \nIt was looking for libcomposite in lsmod output, and trying to modprobe libcomposite if it was not found.<br> \nKnowing that P4wnP1 is very old code, and that I had trouble trying to build it in the past, on top of having near zero Golang experience, I contemplated papering over it by making shims for lsmod that would return the expected output even if libcomposite was a builtin and not a module.<br> \nAfter a few iterations trying to figure out why my changes didn’t solve the problem, I realised that the output of rmmod libcomposite was on stderr, not stdout, and corrected my code.<br> \nUnfortunately, mac80211_hwsim is not currently compiled for the OpenStick, so I can’t do this.<br> \nFor the OpenStick, the LTE interface is available.<br> \nMy solution was to instruct NetworkManager not to try and manage the WiFi interface when P4wnP1 is running, using a systemd service configuration option:<br> \nI ran the following commands to download my HID to TCP proxy, install golang on the OpenStick, and build and run it:<br> ",
    "html_url": "https://sensepost.com/blog/2023/p4wnp1-lte-updates/",
    "text": "After publishing my blog post about running P4wnP1 on an LTE modem, where I explained how to install Linux and P4wnP1 on an actual LTE modem for sneaky USB attacks, and then trying and failing to do an internal presentation to show it off to folks, I realised that I had not completely documented the process. In fact, I had left it rather incomplete as it turned out! As I was intending to give a public demonstration of P4wnP1-LTE, I had some work to do.\n\nUnusable LTE\n\nFirstly, I was unable to get the LTE interface to connect reliably, and pass packets. Having revisited it since that embarrassing internal presentation failure, I now suspect that the problem was strongly linked to the temperature of the LTE modem. To address this, I made use of the commands mentioned at the end of the previous post (chcpu -d 1,2,3) to disable 3 of the 4 cores. This was able to stop the temperatures rising above around 65C, and since doing so, I have had no issues maintaining the LTE connection. cat /sys/class/thermal/*/temp will output the temperatures of the various sensors that the kernel knows about, if you want to check easily.\n\nWhich is not to say that I have had no issues connecting over LTE (using a Vodacom SIM)! In the previous post, I also described setting up a Wireguard VPN to an Internet-accessible host, and then using SSH to access the modem over that VPN. I started noticing that trying to monitor the P4wnP1 logs, or grepping the P4wnP1 code base for certain strings would also result in my SSH connection dying instantly. However, I could immediately reconnect using SSH, so the modem was staying up, and the LTE connection and Wireguard VPN were all “healthy”. Furthermore, when the WiFi link was up, and Wireguard was routing over WiFi, I had no problems running the same commands. What could possibly be the problem?\n\nI started writing a description of the problem in our internal chat to try and solicit debugging suggestions, and while doing so, it struck me that the SSH connection was fine with small amounts of data. I could connect via SSH, authenticate, navigate around the file system, etc. It was not time based, as whether I ran the grep immediately, or after other commands, the lockup behaviour was identical. Large amounts of terminal output would reliably lock up the SSH connection in exactly the same way, every time.\n\nThis didn’t seem to be a problem with downloading files over the LTE connection. I could apt update && apt install with no problems. I recalled a conversation that I had seen a few weeks prior in Discord, where someone described a connection hanging due to an incorrect MTU.\n\nWhat is MTU, though? According to Wikipedia, the maximum transmission unit (MTU) is the size of the largest protocol data unit (PDU) that can be communicated in a single network layer transaction. You can figure out the MTU for a particular interface using ping.\n\nping 8.8.8.8 -c 2 -M do -s 1392\n\nThis sends two ICMP packets to 8.8.8.8, with a data size of 1392 octets (-s 1392), and sets the Path MTU Discovery strategy to prohibit fragmentation (-M do). Basically, this tells any routers not to break up any packets that are too large for the next hop, but rather to return an ICMP error. This allows you to know what the MTU of a particular network path is.\n\nI used this with an ever decreasing packet size to try and figure out what the MTU of my LTE interface was. It was defaulted to something like 1500, but to my surprise, I got all the way down to an ICMP data size of 996 before I was able to successfully get an ICMP response back. Due to ICMP packet framing overhead, you need to add 8 bytes of ICMP and 20 bytes of IPv4 to the data size to calculate the actual MTU. After setting the LTE MTU to 1024, I was able to successfully establish the Wireguard VPN, and SSH connection over LTE, and execute all the commands that were failing previously.\n\nA possible alternative approach is to run tcpdump while downloading something large from the Internet, and seeing what size packets are sent from upstream. One presumes that the Mobile Provider also knows what MTU the link should have, and will only send packets of that maximum size. This is because the MTU is only effective in a single direction, for packets SENT from the system, and doesn’t affect the size of packets received.\n\nA surprising detail though, is that while you normally have to have layered interfaces use a smaller MTU than the underlying interface MTU, in order to account for VPN framing, this does not seem to be the case for Wireguard. Wireguard works just fine over LTE with an MTU of 1420. I’m honestly not sure why or how this works. Maybe Wireguard just fragments the packets anyway?\n\nThe lesson for me there was that taking the time to frame the symptoms I was seeing in a way that someone else could make sense of helped me to solve the problem on my own. The classic Rubber Duck debugging technique strikes again.\n\nRebuilding P4wnP1\n\nSo with the network interfaces now reliable, was I ready for a public presentation? Unfortunately not! It turns out that P4wnP1 has some unmet expectations with regards to the kernel modules that should be available, that I had overlooked in the previous blog post. It was looking for libcomposite in lsmod output, and trying to modprobe libcomposite if it was not found. This works fine on the Raspberry Pi, but fails on the OpenStick distribution, because libcomposite is built in, and not a module. I discovered this by running rmmod libcomposite, and saw that information in the resulting error message. I’m honestly not sure if there is a better way of knowing what is built in, and what modules are available, other than looking for the kernel .config file.\n\nKnowing that P4wnP1 is very old code, and that I had trouble trying to build it in the past, on top of having near zero Golang experience, I contemplated papering over it by making shims for lsmod that would return the expected output even if libcomposite was a builtin and not a module. But I decided to bite the bullet, and at least try to build the codebase with my changes.\n\nThe P4wnP1 code base has a Makefile in the root, so I started there, and tried to make compile. To my dismay, this ended up downloading so many go dependencies, and complaining about things like deprecation, and being unable to find dependencies, even though going to the URL it printed out showed that the dependency was there. Fortunately, Leon, our resident Golang enthusiast, was able to explain that I probably didn’t want the -u option that Mame82 had included when invoking go get. This tells go to update dependencies to newer minor or patch releases. Skipping the updates had everything compile with almost no problems, other than needing to change go get gopherjs to go install gopherjs due to syntax changes.\n\nWith the Makefile updated, and commenting out a bunch of entries designed to install Debian/Kali packages, and made Kali configuration changes for P4wnP1_ALOA, I had P4wnP1 compiled. Except it was compiled for the 64-bit AArch64 Ubuntu installation I was using as a build server, rather than the armv6 architecture needed for the Raspberry Pi (that also runs successfully on the NanoPi R1S and the OpenStick!). Grepping the source for GOARCH, I found a build script at ./build_support/build.sh that did the necessary. After a few iterations trying to figure out why my changes didn’t solve the problem, I realised that the output of rmmod libcomposite was on stderr, not stdout, and corrected my code. Success!\n\nP4wnP1 wants to control the WiFi\n\nWith all of that done, I still faced the problem that P4wnP1 wanted to take over control of the wireless interface from NetworkManager, and implemented the wireless configuration in the same way that it did (successfully) on the Raspberry Pi Zero. I had worked around this on the NanoPi R1S by renaming the real wifi interface to something other than wlan0, and creating a dummy wlan0 with the mac80211_hwsim module. Unfortunately, mac80211_hwsim is not currently compiled for the OpenStick, so I can’t do this. Granted, this is more of an issue for the NanoPi, because the WiFi interface is the only way to access the hardware. For the OpenStick, the LTE interface is available. My solution was to instruct NetworkManager not to try and manage the WiFi interface when P4wnP1 is running, using a systemd service configuration option:\n\nExecStartPre=/usr/bin/nmcli device set wlan0 managed no\nExecStart=/usr/local/bin/P4wnP1_service\nExecStopPost=/usr/bin/nmcli device set wlan0 managed yes\n\nThis tells systemd to run the listed commands before starting and after stopping P4wnP1 respectively, resulting in NetworkManager ignoring the wlan0 interface while P4wnP1 is running. Ideally P4wnP1 should be updated to have an option to ignore the WiFi interface completely, and let the OS manage it instead, as opposed to the current “disable it or manage it” option.\n\nShell over Raw HID\n\nThe last thing to test was the Raw HID channel. I ran the following commands to download my HID to TCP proxy, install golang on the OpenStick, and build and run it:\n\ngit clone https://github.com/RoganDawes/CovertChannel\ncd CovertChannel\ncp Client/PowerShell/helper.js /usr/local/P4wnP1/HIDScripts/covertchannel.js\napt install -y golang socat\ncd Server/Go\ngo run server.go\n\nYou could also cross compile it and copy it across if you prefer, using the same GOARCH, etc flags from building P4wnP1 in the previous section.\n\nWith the CovertChannel server running, I could open another terminal and run socat TCP-L:4444,fork,reuseaddr - to wait for my shell, then go to the P4wnP1 web interface to launch the keystroke injection. Selecting the HIDScript tab, and the “Load and Replace” button, I selected the “covertchannel.js” file that I had just copied. It’s important to include the correct USB VID and PID in the script, so that the PowerShell running on the client knows which device to connect to. Check that they are the same between the HID tab and the last couple of lines of the covertchannel.js script. Then hit Run, and wait for the magic! After a few moments, you should see a lot of activity in the go server terminal, and a DOS Shell prompt appear in your socat terminal. If it doesn’t show up after about 10-15 seconds, try press Enter a couple of times. Enjoy!\n\nIf anyone with Golang skills wants to try and update P4wnP1 to integrate the CovertChannel proxy, and bring the dependencies into the mid twenties, that would be awesome. Integrating the terminal (socat) into P4wnP1 using something like term.js would also be cool, but perhaps quite a lot more work. I do have the start of that work for anyone who wants to to continue, though. Get in touch if this sounds like fun!",
    "title": "P4wnP1 LTE updates"
}
{
    "brief": "post in this series, we’ll take a look at one of CS2BR’s shortcomings: its reliance on source-code for patching.<br> \nSo feel free to grab a coffee and prepare for a journey into the wonderful world of object files, how you can mess with them, and what I did to them.<br> \nI.<br> \nWhen I finished work on CS2BR’s source code patching, I realized that there were two major issues with it that caused me headaches and that I wasn’t happy with:<br> \nSource code: In order to make BOFs compatible with BRC4 in the first place, CS2BR patches a compatibility layer (and some extras) into a BOF’s source code.<br> \nYou’ll then need to recompile the BOF in order to use it in BRC4.<br> \nSince you usually don’t have access to their source code, you can’t use CS2BR to patch them.<br> \nSince BOFs are object files (hence the name, beacon object files) and CS2BR’s compatibility layer can be compiled into an object file, we might just be able to merge both of them into a single object file.<br> \nBefore we continue with the details of this idea, let’s have a brief look at the “Common Object File Format” (COFF) that our object files come in.<br> \nHere’s the source code of a simple BRC4 BOF that prints its input arguments:<br> \nSymbols: Symbols are used to reference various things in object files, such as sections (e.g. .text), functions (e.g. coffee) and imports (e.g. __imp_BadgerDispatch).<br> \nThe first relocation entry in the .text section indicates that at offset 0x46 into the .text section, there is a reference to the .rdata symbol (which points to the .rdata section), which needs to be resolved as a relative address.<br> \nHere’s how the general CS2BR approach works: it provides the CS BOF APIs as part of its compatibility layer.<br> \nThis layer in turn uses the BRC4 BOF APIs which are implemented in the BRC4 badger.<br> \nWhen we patch a BOF’s source code via CS2BR and compile it afterwards, the coffee entrypoint will be included in the BOF and able to invoke the original go entrypoint (*).<br> \nWhen both BOF and the CS2BR compatibility layer are compiled separately though, we need to ensure that those two connections are made when we merge the object files.<br> \nIn order to reference bof.o‘s go entrypoint from cs2br.o, we can leverage the fact that such operations are precisely what object files and linkers are great at accomplishing: by defining go as an external symbol in cs2br.o, a linker will resolve it when also supplying it with bof.o which provides this exact symbol.<br> \nNow, when we compile CS2BR’s entrypoint in badger_stub.c and its compatibility layer beacon_wrapper.h, we observe the resulting cs2br.o‘s symbols.<br> \nIn the previous section we declared go as an external symbol in cs2br.o‘s source code.<br> \ncs2br.o exports BeaconPrintf as a symbol that is contained in section #1 (.text) is a function (ty 20) is at offset 0x5e1 into its section bof.o exports __imp_BeaconPrintf as a symbol that has the __imp_ prefix, indicating that this function was declared using __declspec(import) and needs to be imported at runtime is an external symbol (section value IMAGE_SYM_UNDEFINED) is not a function (ty 0) bof.o also references __imp_BeaconPrintf in a relocation in the .text section.<br> \nWhich makes sense considering that BeaconPrintf is imported from the CS BOF API and its implementation is not included in the BOF’s source code.<br> \nIf we wanted to make the linker resolve these references in bof.o like it did with the go symbol in cs2br.o above, we would need cs2br.o to export not the function implementations but pointers to those implementations.<br> \nHow can we modify parts (such as symbols) of object files?<br> \nSince I wanted to stick with Python for the tooling for this project and couldn’t find a suitable solution for my needs, I decided to implement this functionality based on a Python library I programmed in the past: structex.<br> \nIt’s safe to assume that any program that executes BOFs does that in a way that is somewhat similar to TrustedSec’s COFFLoader.<br> \nNow I could use COFFLoader to run my BOFs and Visual Studio and x64dbg to debug both COFFLoader and my CS2BR BOFs, neat!<br> \nAfter merging both object files, the __imp_ symbols (that originated from bof.o) to CS BOF APIs are replaced with the __cs2br_ symbols (provided by cs2br.o).<br> \nThis will make ld correctly resolve this symbol to the BOF’s entrypoint when we merge both object files.<br> \nThis ensures that, if any of those APIs are used by the BOF, BRC4 imports and links them before executing the BOF.<br> \nWhen I tested my BOFs at that point and saw COFFLoader crashing, I did a lot of manual investigation by debugging COFFLoader and tracing back why it crashed.<br> \nThe 0xDEADBEEFDEADBEF is a dummy value I made COFFLoader pass to the coffee entrypoint to use as the _dispatch variable.<br> \nIt should be pointing to 0x00007FF45D070621 though, as the .text section is mapped to 0x00007FF45D070000 and BeaconPrintf‘s offset into this section is 0x621.<br> \nThere are two .text symbols, of which one has an offset of 0x40 into the .text section.<br> \nThe ADDR64 relocations for the entries in .data could be read as: “Read the relocation’s current value from its offset into .data (aka its ‘addend’), add to it the absolute address of the .text-0x40 symbol, and write the calculated sum back at the relocation entry’s offset in .data.” This doesn’t quite work though: these relocations aren’t relative to a symbol but to the section their symbols reside in.<br> \nare of type IMAGE_REL_AMD64_ADDR64 and are associated to a symbol that doesn’t refer to a section but to an offset within a section (e.g. .text-0x40).<br> \nIt works well in a modified COFFLoader that provides a simple BRC4 BOF API but doesn’t seem to work with BRC4’s badgers.<br> ",
    "html_url": "https://blog.nviso.eu/2023/10/26/introducing-cs2br-pt-iii-knees-deep-in-binary/",
    "text": "This entry is part 3 in the series Introducing CS2BR - Teaching Badgers new Tricks\nIntroduction\n\nOver the span of the previous two blog posts in the series, I showed why the majority of Cobalt Strike (CS) BOFs are incompatible with Brute Ratel C4 (BRC4) and what you can do about it. I also presented CS2BR itself: it’s a tool that makes patching BOFs to be compatible with BRC4 a breeze. However, we also found some limitations to CS2BR’s current approach.\n\nIn this (final?) post in this series, we’ll take a look at one of CS2BR’s shortcomings: its reliance on source-code for patching. We’ll see how this can be resolved and – spoiler alert – why we couldn’t (yet!) but decided to pull the plug on it. That’s right: this blog post won’t present a fancy new solution but the challenges you’ll encounter when you go down this rabbit hole.\n\nThis post will get a bit more technical than its predecessors. Don’t worry though, I’ll try my best not to get lost in itty-bitty details. So feel free to grab a coffee and prepare for a journey into the wonderful world of object files, how you can mess with them, and what I did to them.\n\nI. Underlying motivation\n\nWhen I finished work on CS2BR’s source code patching, I realized that there were two major issues with it that caused me headaches and that I wasn’t happy with:\n\nInput arguments: Supplying BOFs with input arguments in BRC4 isn’t straightforward and requires you to figure out the number and format of arguments, feed them into a standalone Python script, and pass the output into BRC4.\nSource code: In order to make BOFs compatible with BRC4 in the first place, CS2BR patches a compatibility layer (and some extras) into a BOF’s source code. You’ll then need to recompile the BOF in order to use it in BRC4.\n\nWhile the first issue is just somewhat awkward, the second one can be a real showstopper in some cases:\n\nThird party BOFs: There are proprietary, commercial BOFs out there that you might like to use in BRC4, but can’t because they’re incompatible. Since you usually don’t have access to their source code, you can’t use CS2BR to patch them.\nCompilation: Usually BOFs come with limited features and thus don’t require crazy compilation environments. Well, if they do, CS2BR’s source code patching can interfere with that and potentially screw up your compilation configuration. You’d then need to get into the depths of makefiles, build scripts and Visual Studio project configurations to troubleshoot.\n\nSo wouldn’t it be great if we didn’t need access to source code? And wouldn’t it be cool to avoid recompilation of BOFs? There surely has to be a way to do this, right?\n\nII. The idea\n\nSince BOFs are object files (hence the name, beacon object files) and CS2BR’s compatibility layer can be compiled into an object file, we might just be able to merge both of them into a single object file.\n\nAnd indeed, it appears that you can merge object files using ld, the GNU linker:\n\n1\n\t\nld --relocatable cs2br.o bof.o -o brc4bof.o\n\nThat’s the basic premise. Before we continue with the details of this idea, let’s have a brief look at the “Common Object File Format” (COFF) that our object files come in.\n\nAbout COFF\n\nAt their core, object files are an intermediate format of executables: they contain compiled code and data but aren’t directly executable. Here’s the source code of a simple BRC4 BOF that prints its input arguments:\n\n1\n2\n3\n4\n5\n6\n7\n\t\n#include \"badger_exports.h\"\nvoid coffee(char** argv, int argc, WCHAR** dispatch) {\n    int i = 0;\n    for (; i < argc; i++) {\n        BadgerDispatch(dispatch, \"Arg #%i: \\\"%s\\\"\\n\", (i+1), argv[i]);\n    }\n}\n\nThis can be compiled into a COFF file using a C compiler such as mingw on a Linux machine:\n\n1\n2\n3\n4\n\t\n$ x86_64-w64-mingw32-gcc -o minimal.o -c minimal.c\n \n$ file minimal.o        \nminimal.o: Intel amd64 COFF object file, no line number info, not stripped, 7 sections, symbol offset=0x216, 19 symbols, 1st section name \".text\"\n\nWe can get detailed information about the compiled object file using the nd or objdump utilities:\n\nobjdump output\n\nThis gave us quite a lot of information of which I’d like to highlight and unpack three particularly important bits:\n\nSections: These are regions of arbitrary, binary data. Their content is indicated by a section’s name and flags. For example, the .text section with the CODE flag set will usually contain compiled code whereas the .rdata section with the READONLY and DATA flags will contain readonly data (such as strings used in the application).\nSymbols: Symbols are used to reference various things in object files, such as sections (e.g. .text), functions (e.g. coffee) and imports (e.g. __imp_BadgerDispatch).\nRelocations: An object file’s sections can contain references to symbols (and thus to other sections, functions, and imports). When the file is compiled or loaded into memory by a COFF loader such as BRC4, these references need to be resolved to actual relative or absolute memory addresses.\nFor example, the above BadgerDispatch call references the string Arg #%i: \\\"%s\\\"\\n which is located in the .rdata section. The first relocation entry in the .text section indicates that at offset 0x46 into the .text section, there is a reference to the .rdata symbol (which points to the .rdata section), which needs to be resolved as a relative address.\nCOFF section contents dumped using objdump\n\nThese are the central parts of COFF files that are relevant to this blog post.\n\nMerging object files\n\nContinuing with the idea of merging object files, it turns out that it’s not just going to be a simple ld. Let’s compare a regular BOF in Cobalt Strike to a CS2BR BOF in BRC4:\n\nPictured above is a regular CS BOF: It resides in a beacon, is executed via its go entrypoint and can make use of serveral CS BOF APIs. In order to execute the BOF, the beacon acts as a linker: it maps the BOF’s sections into memory, resolves CS BOF API imports to the beacon’s internal implementations and resolves relocations. That’s the regular flow of things.\n\nHere’s how the general CS2BR approach works: it provides the CS BOF APIs as part of its compatibility layer. This layer in turn uses the BRC4 BOF APIs which are implemented in the BRC4 badger. From our perspective, a badger loads & executes a BOF similar to how CS does.\n\nWhen we patch a BOF’s source code via CS2BR and compile it afterwards, the coffee entrypoint will be included in the BOF and able to invoke the original go entrypoint (*). Additionally, calls to the CS BOF API will be “rerouted” to CS2BR’s compatibility layer (*). When both BOF and the CS2BR compatibility layer are compiled separately though, we need to ensure that those two connections are made when we merge the object files. For simplicity’s sake, let’s refer to the compiled CS BOF as bof.o and to the compiled CS2BR compatibility layer as cs2br.o:\n\nEntrypoint: The coffee entrypoint in cs2br.o needs to reference the go entrypoint in bof.o. When the files are merged, this reference must be resolved.\nAPIs: The CS BOF APIs imported in bof.o must be “re-wired” so they don’t reference imports but cs2br.o‘s implementations instead.\n\nWell, this doesn’t sound super complicated, does it?\n\nIII. Execution\n\nNow it’s only a matter of putting everything together. We’ll start with the entrypoint:\n\nPreparing the entrypoint\n\nIn order to reference bof.o‘s go entrypoint from cs2br.o, we can leverage the fact that such operations are precisely what object files and linkers are great at accomplishing: by defining go as an external symbol in cs2br.o, a linker will resolve it when also supplying it with bof.o which provides this exact symbol. So here’s the single line we add to CS2BR’s badger_stub.c that contains our custom coffee entrypoint:\n\n1\n\t\nextern void go(void *, int);\n\nNow, when we compile CS2BR’s entrypoint in badger_stub.c and its compatibility layer beacon_wrapper.h, we observe the resulting cs2br.o‘s symbols. Also, for comparison, let’s also inspect bof.o‘s symbols:\n\n1\n2\n3\n4\n5\n\t\n$ objdump -x cs2br.o | grep go  \n[ 52](sec  0)(fl 0x00)(ty   20)(scl   2) (nx 0) 0x0000000000000000 go\n \n$ objdump -x bof.o | grep go\n[  2](sec  1)(fl 0x00)(ty   20)(scl   2) (nx 1) 0x0000000000000000 go\n\nWe can use Microsoft’s documentation on the PE format (which also covers COFF) to better understand what those entries mean:\n\nsec: “The signed integer that identifies the section, using a one-based index into the section table. Some values have special meaning […].”\nValue 0 (IMAGE_SYM_UNDEFINED): “[…] A value of zero indicates that a reference to an external symbol is defined elsewhere. […]”\nty: “A number that represents type. Microsoft tools set this field to 0x20 (function) or 0x0 (not a function). […]”\nThe value (hex value before the symbol name): “The value that is associated with the symbol. The interpretation of this field depends on SectionNumber and StorageClass. A typical meaning is the relocatable address.”\nscl: “An enumerated value that represents storage class. […]”\nValue 2 (IMAGE_SYM_CLASS_EXTERNAL): “[…] The Value field indicates the size if the section number is IMAGE_SYM_UNDEFINED (0). If the section number is not zero, then the Value field specifies the offset within the section.”\n\nUsing this information, we can deduct that:\n\ncs2br.o‘s go symbol is an external symbol defined elsewhere.\nbof.o‘s go symbol is located in section 1 (.text) and located right at the start of the section (offset 0).\n\nWhen we merge them using ld (ld --relocatable bof.o cs2br.o -o brbof.o --oformat pe-x86-64) and inspect them in a disassembler like Ghidra, we see that the linking worked as expected and cs2br.o‘s coffee actually calls bof.o‘s go:\n\nNice, the first thing is done. This was pretty easy!\n\nRewiring CS BOF API imports\n\nIn the previous section we declared go as an external symbol in cs2br.o‘s source code. This allowed us to have the linker resolve the reference to the supplied bof.o‘s implementation of go.\n\nRewiring the CS BOF API imports of bof.o to cs2br.o‘s implementations isn’t as straightforward though. Let’s have a look at the symbols involved:\n\n1\n2\n3\n4\n5\n6\n\t\n$ objdump -x cs2br.o | grep BeaconPrintf\n[ 24](sec  1)(fl 0x00)(ty   20)(scl   2) (nx 0) 0x00000000000005e1 BeaconPrintf\n \n$ objdump -x bof.o | grep BeaconPrintf                                                \n[ 18](sec  0)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000000 __imp_BeaconPrintf\n0000000000000027 IMAGE_REL_AMD64_REL32  __imp_BeaconPrintf\n\nFrom this output we learn that:\n\ncs2br.o exports BeaconPrintf as a symbol that\nis contained in section #1 (.text)\nis a function (ty 20)\nis at offset 0x5e1 into its section\nbof.o exports __imp_BeaconPrintf as a symbol that\nhas the __imp_ prefix, indicating that this function was declared using __declspec(import) and needs to be imported at runtime\nis an external symbol (section value IMAGE_SYM_UNDEFINED)\nis not a function (ty 0)\nbof.o also references __imp_BeaconPrintf in a relocation in the .text section. Which makes sense considering that BeaconPrintf is imported from the CS BOF API and its implementation is not included in the BOF’s source code.\n\nThe fact that __imp_BeaconPrintf referes to an import makes it special and more tricky to handle:\n\nContrary to how cs2br.o called go (which was a call to an address relative to the CALL statement), bof.o calls BeaconPrintf by absolute address that is read from the place in memory where __imp_BeaconPrintf is located. In other words, __imp_BeaconPrintf is a pointer to the actual implementation and a loader needs to calculate and populate this address at runtime.\n\nIf we wanted to make the linker resolve these references in bof.o like it did with the go symbol in cs2br.o above, we would need cs2br.o to export not the function implementations but pointers to those implementations. Then we’d still need to rename all the imported functions in bof.o so they don’t have the __imp_ prefix in their names anymore or else a loader might attempt to import them again (and fail doing so).\n\nThere are two major challenges to this though:\n\nHow can we modify parts (such as symbols) of object files? The GNU utilities I found so far only allowed me to read but not write them.\nHow can we debug merged object files? When we just execute any merged BOF via a BRC4 badger, the badger might just not output anything (in the best case) or straight up crash on us (in the worst case).\n\nI’ll cover those next before continuing with the process of merging object files.\n\nIV. Getting the right tools for the job\n\nAs outlined above, there are two major challenges related to the tooling I needed to overcome at this point.\n\nReading/writing COFF: structex\n\nThere are lots of COFF parsers out there that allow you to parse existing or create new COFF files. Only very few also allow for modification of existing files though. Since I wanted to stick with Python for the tooling for this project and couldn’t find a suitable solution for my needs, I decided to implement this functionality based on a Python library I programmed in the past: structex.\n\nThe idea of structex is that, as a developer, you don’t imperatively write down code to serialize or deserialize individual fields of data structures but instead describe the data structure to your application. The library then does the heavy-lifting and figures out which field is at what offset and does all the (de-)serialization for you. Then you can just have your application map data structures to some binary buffer and access fields of those structures like you access fields in Python classes. Here’s a brief example:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\t\nclass MachineType(IntEnum):\n    IMAGE_FILE_MACHINE_I386 = 0x014c\n    IMAGE_FILE_MACHINE_IA64 = 0x0200\n    IMAGE_FILE_MACHINE_AMD64 = 0x8664\n \nclass coff_file_header(Struct):\n    # ...\n    _machine: int = Primitive(uint16_t)\n    NumberOfSections: int = Primitive(uint16_t)\n    #...    \n \n    @property\n    def Machine(self) -> MachineType:\n        return MachineType(self._machine)\n \n# Load BOF into memory & parse header\nmemory = BufferMemory.from_file('bof.o')\nbof_header = coff_file_header(memory, 0)\n \nprint(bof_header.Machine.name)\n# Prints: IMAGE_FILE_MACHINE_AMD64\nbof_header.NumberOfSections = 0\n \n# Write modified BOF back to disk\nmemory.to_file('bof_modified.o')\n# bof_modified.o has now set its NumberOfSections to 0\n\nAll that I needed to do then was write down the data structures used in COFF, add some property decorators for even easier handling, and implement some bits of custom logic (e.g. reading & modifying the COFF string table). This allowed me to easily parse, inspect and modify any BOF files.\n\nDebugging BOFs: COFFLoader\n\nImplants are mainly designed to operate covertly, leave very few traces, and avoid getting noticed (and for that matter, sometimes even actively evade detection). This can make them hard to locate, observe and make sense of – not exactly ideal conditions for debugging. So I went out looking for alternatives.\n\nIt’s safe to assume that any program that executes BOFs does that in a way that is somewhat similar to TrustedSec’s COFFLoader. So why not use COFFLoader then? Well, it doesn’t support BRC4’s BOF API. Considering that COFFLoader is open source and the BRC4 API is pretty limited (as shown in our first blog post TODO: Insert link), it wasn’t terribly difficult to implement that functionality. I basically only needed to\n\nprovide simple implementations of the BRC4 APIs,\nupdate COFFLoader’s InternalFunctions array to point to the Badger* APIs,\nupdate hardcoded uses of the length of InternalFunctions,\nupdate the check for symbol prefixes to check for the Badger prefix and\nupdate the signature and exact call of the BOF entrypoint.\n\nSince I didn’t want to spend much time on this, I kept the implementations of the BRC4 APIs very simple and didn’t add any sanity checks (or even proper formatting):\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\t\nsize_t BadgerStrlen(CHAR* buf) { returnstrlen(buf); }\nsize_t BadgerWcslen(WCHAR* buf) { return wcslen(buf); }\nvoid* BadgerMemcpy(void* dest, const void* src, size_t len) { return memcpy(dest, src, len); }\nvoid* BadgerMemset(void* dest, int val, size_t len) { return memset(dest, val, len); }\nint BadgerStrcmp(const char* p1, const char* p2) { return strcmp(p1, p2); }\nint BadgerWcscmp(const wchar_t* s1, const wchar_t* s2) { return wcscmp(s1, s2); }\nint BadgerAtoi(char* string) { return atoi(string); }\nPVOID BadgerAlloc(SIZE_T length) { return malloc(length); }\nVOID BadgerFree(PVOID* memptr) { free(*memptr); }\nBOOL BadgerSetdebug() { return TRUE; }\nULONG BadgerGetBufferSize(PVOID buffer) { return 0; }\n \nint BadgerDispatch(WCHAR** dispatch, const char* __format, ...) {\n    va_list args;\n    va_start(args, __format);\n    vprintf(__format, args);\n    va_end(args);\n}\nint BadgerDispatchW(WCHAR** dispatch, const WCHAR* __format, ...) {\n    va_list args;\n    va_start(args, __format);\n    vwprintf(__format, args);\n    va_end(args);\n}\n\nI’m not very familiar with using gbd for debugging and do most of my coding in Visual Studio and Visual Studio Code and debugging in x64dbg. That’s why I also used this opportunity to set up COFFLoader as a Visual Studio solution. Now I could use COFFLoader to run my BOFs and Visual Studio and x64dbg to debug both COFFLoader and my CS2BR BOFs, neat!\n\nV. Finally: The CS2BR Binary Patching Workflow\nRE: Rewiring CS BOF APIs\n\nOn the matter of actually rewiring CS BOF API imports, there are two things to consider:\n\nThe relocations to the imports themselves are relative to the instruction using/calling them.\nThe imports referenced by the code are pointers to the actual implementations.\n\nWriting this, I realize that all of this sounds pretty abstract, so let’s have a look at an example:\n\nOur bof.o sends text back to operators by using the BeaconPrintf API. Because of that, bof.o imports the API by defining a __imp_BeaconPrintf symbol. This symbol refers to a place in memory where a pointer to the actual BeaconPrintf is stored.\n\nFor binary patching in CS2BR this means that we need to overwrite these pointers in bof.o to the actual implementations somehow so they point to CS2BR’s methods. These pointers are set by the loader (e.g. COFFLoader) though and that’s something we can’t control before or even at compile-time. So the question becomes: How can we make the loader point imports to CS2BR’s methods instead?\n\nAfter staring at Ghidra, x64dbg, objdump output and my Python source code for more days than I’m comfortable to admit, I worked out a solution to this problem. It consists of some preparations and two processing phases that I’ll further detail in the following paragraphs.\n\nThe general idea is pretty simple:\n\nCS2BR defines pointers (prefixed with __cs2br_) to its compatibility layer’s methods. These pointers will also end up in its symbol table. After merging both object files, the __imp_ symbols (that originated from bof.o) to CS BOF APIs are replaced with the __cs2br_ symbols (provided by cs2br.o). This leaves us with symbols that are referenced relative to instructions and contain pointers to our desired CS2BR compatibility layer methods.\n\nHere’s how the complete workflow is implemented in CS2BR:\n\n1. Declaring the go entrypoint\n\nAs described earlier in this blog post, the compiled CS2BR object file needs to contain an external reference to the go entrypoint. To do so, I just added the a declaration of this method to CS2BR’s the stub: extern void go(void *, int);\n\nThis will make ld correctly resolve this symbol to the BOF’s entrypoint when we merge both object files.\n\n2. Creating proxy symbols\n\nNext, I added pointers to all of the CS BOF APIs implemented in CS2BR’s compatibility layer:\n\n1\n2\n3\n4\n\t\nvoid* __cs2br_BeaconDataParse __attribute__((section(\".data\"))) = &BeaconDataParse;\nvoid* __cs2br_BeaconDataInt __attribute__((section(\".data\"))) = &BeaconDataInt;\nvoid* __cs2br_BeaconDataShort __attribute__((section(\".data\"))) = &BeaconDataShort;\n// ...\n3. Preprocessing the BOF\n\nBefore merging object files, CS2BR identifies all CS BOF API import symbols (named __imp_Beacon*) and reconfigures them:\n\n1\n2\n3\n4\n5\n6\n7\n8\n\t\nfor symbol_name in cs_patches:\n  symbol = osrcbof.get_symbol_by_name(f\"__imp_{symbol_name}\")\n  symbol.Value = 0\n  symbol.SectionNumber = 0\n  symbol.StorageClass = StorageClassType.IMAGE_SYM_CLASS_EXTERNAL\n  symbol.Name = symbol_name\n  symbol.Name = f\"__cs2br_{symbol_name}\"\n  symbol._type = 0\n\nThis reconfiguration achieves that the symbols are\n\ntreated as external (section number 0, storage class IMAGE_SYM_CLASS_EXTERNAL, type 0) and\nrenamed from __imp_* to __cs2br_*, which alles ld to resolve them to cs2br.o‘s defined symbols upon merging.\n\nThen CS2BR renames the symbols of windows APIs that are available to CS BOFs by default (LoadLibrary, GetModuleHandle, GetProcAddress and FreeLibrary) so they have the __imp_KERNEL32$ prefix. This ensures that, if any of those APIs are used by the BOF, BRC4 imports and links them before executing the BOF.\n\n4. Merging both object files\n\nBoth object files (bof.o and cs2br.o) are merged using ld. The resulting object file contains the sections and symbols of both files.\n\n5. Recalculating ADDR64 relocations\n\nAt this point, both COFFLoader and BRC4 should be able to load and execute the patched BOF. Instead, COFFLoader just crashed and BRC4 gave me the silent treatment.\n\nIt turned out that the relocations were flawed and presumably not recalculated by ld. I’ll briefly describe that bug right now, you can skip to my workaround if you want to.\n\nBroken relocations\n\nRelocations are a tricky topic. In fact I don’t think I got my head fully wrapped around the topic myself. When I tested my BOFs at that point and saw COFFLoader crashing, I did a lot of manual investigation by debugging COFFLoader and tracing back why it crashed. Let’s have a look at an example:\n\nWe’ll execute a very simple BOF that only formats and outputs a string using BeaconPrintf:\n\n1\n2\n3\n4\n5\n6\n7\n\t\n#include <windows.h>\n#include \"beacon.h\"\n \nVOID go(IN PCHAR Args,  IN ULONG Length) {\n    BeaconPrintf(CALLBACK_OUTPUT, \"Hi from CS2BR %i\\n\", 1337);  \n    return;\n}\n\nWhen executing the BOF in COFFLoader, it would end up executing some data, not actual instructions:\n\nInspecting the address of RIP in the dump, we can see that RIP lies in the .rdata section of the BOF as we can clearly see the strings used in cs2br.o‘s entrypoint:\n\nBy restarting and carefully stepping through the program we see that the coffee entrypoint is invoked correctly, so that bit works just fine:\n\nIt also reaches the go entrypoint:\n\nThe next call will fail though. It retrieves the address of the method to call from a pointer (mov rax, qword ptr ds:[7ff45d050068]) and calls that. Taking a look at the memory dump of the address of the pointer, we see that this is our .data section:\n\nThe 0xDEADBEEFDEADBEF is a dummy value I made COFFLoader pass to the coffee entrypoint to use as the _dispatch variable. CS2BR saves this _dispatch variable as a global variable in .data as can be seen in the objdump output:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\t\n$ objdump -x minimal.BR_bin21.o | grep \"sec  3\"\n \n[ 36](sec  3)(fl 0x00)(ty    0)(scl   3) (nx 1) 0x0000000000000000 .data\n...\n 0x0000000000000068 __cs2br_BeaconPrintf\n[ 43](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000050 __cs2br_BeaconFormatPrintf\n[ 44](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000088 __cs2br_BeaconIsAdmin\n[ 45](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000000 _dispatch\n[ 46](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000070 __cs2br_BeaconOutput\n[ 47](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0)\n...\n\nAs expected, the call fails at this point as it jumps to 0x00007FF45D0705E1 which is just some random offset into a method:\n\nIt should be pointing to 0x00007FF45D070621 though, as the .text section is mapped to 0x00007FF45D070000 and BeaconPrintf‘s offset into this section is 0x621. Apparently, the value of the pointer to BeaconPrintf is a whopping 0x40 bytes short. This left me confused for quite a while. And just by accident, I noticed something in the objdump output:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\t\nSections:\nIdx Name          Size      VMA               LMA               File off  Algn\n  0 .text         00000dc0  0000000000000000  0000000000000000  000000b4  2**4\n                  CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE\n...\n  5 .data         00000200  0000000000000000  0000000000000000  00001380  2**5\n                  CONTENTS, ALLOC, LOAD, RELOC, DATA\n...\n \nSYMBOL TABLE:\n...\n[  2](sec  1)(fl 0x00)(ty    0)(scl   3) (nx 1) 0x0000000000000000 .text\n...\n[ 28](sec  1)(fl 0x00)(ty   20)(scl   2) (nx 0) 0x0000000000000621 BeaconPrintf\n...\n[ 34](sec  1)(fl 0x00)(ty    0)(scl   3) (nx 1) 0x0000000000000040 .text\n...\n[ 42](sec  3)(fl 0x00)(ty    0)(scl   2) (nx 0) 0x0000000000000068 __cs2br_BeaconPrintf\n...\n \n \nRELOCATION RECORDS FOR [.text]:\nOFFSET           TYPE              VALUE\n...\n0000000000000027 IMAGE_REL_AMD64_REL32  __cs2br_BeaconPrintf-0x0000000000000068\n...\n \n \nRELOCATION RECORDS FOR [.data]:\nOFFSET           TYPE              VALUE\n...\n0000000000000068 IMAGE_REL_AMD64_ADDR64  .text-0x0000000000000040\n...\n\nDid you spot it? There are two .text symbols, of which one has an offset of 0x40 into the .text section. That same odd symbol is used in relocations of the __cs2br_* symbols.\n\nThe ADDR64 relocations for the entries in .data could be read as: “Read the relocation’s current value from its offset into .data (aka its ‘addend’), add to it the absolute address of the .text-0x40 symbol, and write the calculated sum back at the relocation entry’s offset in .data.” This doesn’t quite work though: these relocations aren’t relative to a symbol but to the section their symbols reside in. Thus, COFFLoader correctly resolves the relocation to the address of the .text section plus the relocation’s addend 5E1. We know the relocation’s addend is 5E1 by simply extracting it:\n\n1\n2\n3\n4\n\t\n# 5096 is the decimal representation of 1380h (.data offset into the file) + 68h (relocation offset)\nod -j 5096 -N 8 -t x8 minimal.BR_bin.o\n0011750 00000000000005e1\n0011760\n\nHere’s where the workaround finally comes into play!\n\n(Cont:) 5. Rebasing ADDR64 relocations\n\nLastly, CS2BR recalculates relocations that\n\nare of type IMAGE_REL_AMD64_ADDR64 and\nare associated to a symbol that doesn’t refer to a section but to an offset within a section (e.g. .text-0x40).\n\nFor each of those relocations, it will acquire their current addend, add to it the value of the associated symbol, and write the newly calculated addend back to the image, as can be seen here with the __cs2br_BeaconPrintf symbol:\n\n1\n\t\n[INFO] Pointing relocation .data:0x68 from .text:0x40+0x5e1 (=> __cs2br_BeaconPrintf) to .text:0x621 (=> BeaconPrintf)...\nVI. Demo\n\nPatching a BOF using cs2br is very simple. One only needs to compile the compatibility layer (cs2br.o) and supply & run the patchbin.py script with paths to the BOF file to patch and the cs2br.o:\n\nRunning a BOF that was binary-patched by CS2BR works great in COFFLoader:\n\nNot so much in BRC4 though:\n\nAt this point, there wasn’t much I could do. I certainly didn’t feel like putting more work into it and testing against a black box didn’t make much sense.\n\nI did reach out to Chetan Nayak, the developer of BRC4, via Discord a couple of times during the project. Since this was an internal project at the time however, I couldn’t share CS2BR’s source code. Provided with a fully patched binary, they said the entrypoint was not found and never executed by the badger. Apparently, debugging this blob could take a lot of time and they can’t provide support for such BOFs.\n\nThis marks the end of my work on this project – for now.\n\nVII. Conclusion & Outlook\n\nThis was one long blog post to write. Working on the tool and debugging BOFs certainly took a long time – I honestly underestimated the effort of documenting all of it in this post though. So, let’s have a look at what CS2BR accomplished:\n\nCS2BR’s source-code patching approach works very well and enables operators to use well-known and battle-tested BOFs that were formerly (almost) exclusive to CS now in BRC4. While it requires access to source code and recompilation of BOFs, it does provide a solid compatibility layer.\n\nIn its current iteration, CS2BR is able to patch binary CS BOFs and make them (on paper!) compatible with BRC4. It works well in a modified COFFLoader that provides a simple BRC4 BOF API but doesn’t seem to work with BRC4’s badgers. The reason as to why it doesn’t is a mystery to me. As such, this iteration of CS2BR effectively isn’t usable. Since this is an open-source project, everyone is free to have a look for themselves and maybe someone finds a solution – in which case I would be thrilled to learn all about it!\n\nBoth approaches, the source-code and binary patching, make use of the same custom entrypoint which, depending on the exact BOF being executed, requires encoding input parameters with the provided Python script. It would be nice to automate parts of those by parsing the CNA scripts that accompany the BOFs and making use of the BRC4 Ratel Server API to simplify the process.\n\nAfterthoughts\n\nTo me, this project was a rewarding, albeit intense and at times frustrating, journey and deep-dive into BOF development and the COFF format. I certainly learned a lot! To be frank though, the fact that this isn’t a success-story leaves me quite unsatisfied.\n\nI’ll be laying down my work on this project for now and provide support for the source-code patching approach. Maybe some day Chetan finds some time to look into his BOF loader, though, and lets me know what’s wrong with CS2BR’s approach to patching.\n\nSince you made it this far, I can only assume that you are very interested in the topic (or skipped a fair bunch of this blogpost). I would love to know your thoughts on the topic, so please leave a reply!\n\nMoritz Thomas\n\nMoritz is a senior IT security consultant and red teamer at NVISO.\nWhen he isnât infiltrating networks or exfiltrating data, he is usually knees deep in research and development, working on new techniques and tools in red teaming.\n\nLinkedIn\nSeries Navigation\n<< Introducing CS2BR pt. II – One tool to port them all\nShare this:\nTwitterRedditWhatsAppEmail\nLike this:\nLoading...",
    "title": "Introducing CS2BR pt. III – Knees deep in Binary"
}
