{
    "brief": "Yet, the reality was very different. In her HR role, Bonny conveyed that Kristina had recommended me for the job. Skepticism arose when I discovered Kristina had used the WhatsApp alias “Ava.” To address my doubts, Bonny presented a screenshot of her chat with Ava (or Kristina), leading to an unforeseen twist. Shortly afterward, Bonny presented me with the so-called job, which was, in reality, the scam. Following the process, I sent her a screenshot as directed and already had 20 USDT in my digital wallet to kickstart my work. She then gave instructions for a straightforward process: My main task was to activate the work wizard by choosing “Launch Evolution” and clicking “Evolve” for the listed apps. The Illusion of Executive Applications She informed me that she would withdraw the entire balance from the training account, which she had financed. To continue working, I had to contact customer service and provide my training account’s username. Bonny even disclosed her daily earnings, fostering a sense of camaraderie. During my engagement, Bonny took on various roles. In addition, I changed the withdrawal wallet address to my own before Bonny had the opportunity to empty the training account. And everything Bonny had shown me was fake, with not a single dollar ever being transferred during my training. The crucial factor is in the training phase, where the guide convincingly shows that the system not only works but also brings in profits. What’s interesting about this psychological manipulation is that it not only gives the illusion of making money but also triggers a surge of positive emotions. If you approach the scam with skepticism, it’s easy to lose that doubt during the training and start believing that it works. That’s exactly what the scammers want—to make you believe in the illusion of success, prompting you to deposit money into your account and unintentionally lose it. But for those who have fallen into this or a similar trap, it’s crucial to contact the relevant authorities and law enforcement for help. As the virtual world keeps advancing, so should our awareness, skepticism, and ability to bounce back. It serves as evidence of the dynamics between the virtual and the real, and a reminder that, in our digital age, it’s not just our passwords that require protection, but our understanding and suspicion as well.",
    "html_url": "https://blog.compass-security.com/2023/12/exposing-the-scammers-unmasking-the-elaborate-job-offering-scam/",
    "text": "In the era of the internet, scams vary in forms, targeting those who aren’t cautious. Lately, a fresh scam focused on Switzerland has gained attention on social media and in the news. This scam revolves around job offers from a seemingly genuine headhunting company. I chose to engage with the scammers to uncover the secrets of this scheme. Here’s what happened.\n\nHeadhunting for the Chief of Victims\n\nMy curiosity drove me to explore the deceptive realm of job scams, keen to understand their workings and motivations. I got a WhatsApp message from someone named Kristina, alleging to represent vChiefs, a genuine executive headhunting company seeking fresh talent. Yet, the reality was very different.\n\nAlthough vChiefs is a real company, focusing on recruiting top executives for C-level roles, those behind the messages were evidently not scouting for corporate leaders. Instead, they aimed to trap victims in a fraudulent scheme, luring them with payments in USDT, a cryptocurrency tied to the US dollar.\n\nAt first, I opted for a bit of amusement, adopting a playful Italian-sounding alias in our conversation. Unfortunately, the scammer doesn’t speak Italian and directed me to their HR department, promising contact from someone named Bonny.\n\nIn her HR role, Bonny conveyed that Kristina had recommended me for the job. Skepticism arose when I discovered Kristina had used the WhatsApp alias “Ava.” To address my doubts, Bonny presented a screenshot of her chat with Ava (or Kristina), leading to an unforeseen twist.\n\nThe screenshot displayed numerous Chinese characters, hinting that the scammers could be operating from an Asian country, possibly China. Despite this, I chose to continue and observe where this scam would lead.\n\nLet the Games begin\n\nShortly afterward, Bonny presented me with the so-called job, which was, in reality, the scam. She outlined a training session lasting 10 to 30 minutes, but little did I know, it would occupy my entire evening. But first, they showcased the potential earnings.\n\nYou start on a Bronze level, providing an opportunity to progress through Silver, Gold, and Platinum tiers based on earnings. The higher the tier, the more substantial the profits and responsibilities. Bonny also introduced me to MMC, the alleged company behind this opportunity, supported by an intriguing yet perplexing promotional video.\n\nWelcome to the Nonsensical\n\nIt left me puzzled, resembling a mix of arbitrary text with sporadic mentions of blockchain technology. Nevertheless, I was prepared for the actual work ahead.\n\nBonny gave me a website URL and a referral code for registration, accompanied by detailed instructions. Following the process, I sent her a screenshot as directed and already had 20 USDT in my digital wallet to kickstart my work. Once the initial steps were done, I forwarded Bonny my referral code to establish a training account in my name. She then provided the login details for our shared account.\n\nBonny always asked for screenshots and I didn’t want to look like a professional.\n\nGetting Down to Business\n\nBonny kickstarted the work by generously adding 1000 USDT to my account, elevating my status to Silver which increased earnings. She then gave instructions for a straightforward process: My main task was to activate the work wizard by choosing “Launch Evolution” and clicking “Evolve” for the listed apps.\n\n\nEach app presented its “Total” price and computed “Profits,” correlating with my Silver-level. With each “Evolve” click, my balance initially decreased by the app’s “Total” price, only to increase again by both the “Total” and the “Profits.” Essentially, each evolution I executed led to a net gain, intensifying my fascination with this scam.\n\nThe Illusion of Executive Applications\n\nEverything seemed to be going smoothly until, after around 29 successful clicks, my status suddenly changed to “Pending.” Confused, I reached out to Bonny for clarification.\n\nShe promptly responded, explaining that I had received a “random gift” of an “Executive Application.” She emphasized the rarity and benefit of this occurrence, although it left me stuck. Bonny elaborated that Executive Applications, though expensive, promised four times the usual profits. To continue, I would need to fund my account to cover the associated costs, and Bonny kindly offered to assist me with the process.\n\nFirst, I had to contact customer service via WhatsApp or Telegram, sharing the training account’s username and requesting a status check. Customer service quickly responded, instructing me to transfer several hundred dollars to a designated wallet. I relayed the information to Bonny, who executed the transaction, topping up my account and allowing me to continue.\n\nThis cycle repeated a few times as I encountered more applications. Bonny assured me of my good fortune in receiving numerous Executive Applications in a single day.\n\nMission Accomplished: Or So It Seemed\n\nWith my training completed, Bonny expressed her pride in my progress. She informed me that she would withdraw the entire balance from the training account, which she had financed. I was now set to venture into this job on my own, tasked evolving applications and accumulating profits. However, this newfound independence came with a hidden twist.\n\nSome applications carried a “Total” cost that exceeded my current balance, just like the “Executive Applications” before, causing it to dip into the negative. This is when the truth of the scam came into focus: In contrast to the guided training phase where Bonny had conveniently handled such issues, I was now compelled to tackle the situation independently.\n\nTo continue working, I had to contact customer service and provide my training account’s username. Their response was prompt and what I was expecting all along: I was told to top up the negative balance by transferring real money into their wallet. This marked a critical moment where the scammers aimed for me to take the bait, investing my own funds in hope of illusory profits.\n\nBuilding Virtual Bonds\n\n\nWhile engaging in authentic tasks, Bonny extended an invitation to join the “recreational group.” This community comprised 15-20 members. Discussions ranged from finances and work to gaming, food, and more. It was a diverse group that provided an opportunity to connect with others while earning. Bonny even disclosed her daily earnings, fostering a sense of camaraderie.\n\nDuring my engagement, Bonny took on various roles. Following my initial day of work, she playfully criticized me for sending what she deemed ‘very low-quality pictures and screenshots.’ The following morning, as part of her routine, she shared an emotional quote: ‘Good morning! What can be more blissful than waking up to God’s graces? Have a blessed day.’ These daily quotes aimed to inspire and motivate, fostering emotional connections between us and in the group.\n\nBonny persistently encouraged me to initiate my work, assuring that success was within reach. She even went to the extent of offering help in setting up a wallet to deposit my money into their system. Her dedication to keeping me engaged and involved in the scam remained steadfast.\n\nIn a notably surprising twist, Bonny took the initiative to make a phone call one day. Identifying herself as Bonny, she inquired if I had some free time for a chat. However, it became apparent that the voice on the other end lacked the authenticity of a real person. It bore a distinct robotic tone, despite its female characteristics, adding another layer of deception to the whole story.\n\nThe Deceptive Truth Revealed\n\nHowever, behind this facade of camaraderie lay a web of deception. During and after my training I continuously tracked the transactions to the designated wallet addresses, only to discover that no money had ever been transferred. In addition, I changed the withdrawal wallet address to my own before Bonny had the opportunity to empty the training account. Yet, no transactions ever happened.\n\nIn order to change the withdrawal address, I noticed that my profile had a section for editing details, including the withdrawal wallet address. Initially, it appeared that Bonny had pre-filled this and it couldn’t be changed without a security password. However, due to my security analyst background, I had already uncovered the withdrawal password at the beginning of the ordeal. This not only allowed me to modify the withdrawal address discreetly but also exposed a significant security flaw on their part. And everything Bonny had shown me was fake, with not a single dollar ever being transferred during my training.\n\nWhy It Works\n\nThe basic truth is, you can’t make money magically. The scammers make up apps with different levels of popularity and fake prices. When you think about it seriously, you can see it’s just a big lie. But, why do people still fall for it?\n\nThe crucial factor is in the training phase, where the guide convincingly shows that the system not only works but also brings in profits. Every transaction Bonny made appeared to boost my balance, creating a false sense of legitimacy. What’s interesting about this psychological manipulation is that it not only gives the illusion of making money but also triggers a surge of positive emotions. The Executive Applications, portrayed as rare, special, and symbols of good luck, are cleverly integrated into the story, fostering a sense of pride and accomplishment.\n\nIf you approach the scam with skepticism, it’s easy to lose that doubt during the training and start believing that it works. That’s exactly what the scammers want—to make you believe in the illusion of success, prompting you to deposit money into your account and unintentionally lose it.\n\nFurthermore, the group of fellow participants seems to consist of real people, creating an environment that seems genuine. However, it’s highly probable that these individuals are just as imaginary as the scam itself.\n\nKey Takeaways\n\nIn the larger picture, my dive into the heart of this tricky online scam wasn’t just a story of deceit and fascination; it was a profound lesson in digital literacy and human behavior. The experience highlighted the crucial need to be careful in our increasingly connected world.\n\nAs things calmed down and I looked at the pieces of this misleading puzzle, it was clear that the effectiveness of deception doesn’t just come from technical skill but also from taking advantage of our psychological weaknesses. The scammers targeted our natural desires for success, wealth, and belonging, crafting an environment that played into these aspirations.\n\nIf you come across such a scam, the best thing to do is report it as spam and block the sender. But for those who have fallen into this or a similar trap, it’s crucial to contact the relevant authorities and law enforcement for help. These scammers operate globally, and only through a combined effort can they be held accountable.\n\nMy exploration into the core of this online scam, though unusual, was an eye-opener—a chance to expose the workings of deception and untangle the intricate threads of human psychology. As the virtual world keeps advancing, so should our awareness, skepticism, and ability to bounce back. In a realm where illusions can pretend to be reality, we need to stay watchful, careful, and most importantly, digitally savvy.\n\nI hope you found this account both enlightening and entertaining. It serves as evidence of the dynamics between the virtual and the real, and a reminder that, in our digital age, it’s not just our passwords that require protection, but our understanding and suspicion as well. Stay vigilant, stay informed, and above all, stay safe!",
    "title": "Exposing the Scammers: Unmasking the Elaborate Job Offering Scam"
}
{
    "brief": "Remote RPC Attacks – Detection Remote RPC Attacks – Prevention Components of the RPC Firewall Create an RPC Filter/Firewall rule Identify UUID and Operation number of an RPC call Identifying allowed endpoints Identifying possible actions Checking the current status of the Local Security Authority (LSA) Protection Check by using the registry Rule creation with LSA Protection enabled (RPC filters) Rule creation with LSA Protection disabled (Firewall) Deployment References Steffen Rogge Why should we care? When the RPC firewall configuration is configured to audit, RPC events are written to the Windows Event Log and allow for a forward to a central detection and analysis platform. The rpcFwManager.exe is the main executable that is being used by the RPC Firewall service in the deployment but is also used to reload the changed configuration. The file rpcMessages.dll is a common library file used for logic that is shared between the other components and responsible for creating and writing the events to the Windows Event log. In order to create a rule we do need the UUID for the affected interface and we can find that information here: This also means that we do not want our RPC firewall to block legitimate RPC calls and thus prevent the DCSync and cause problems in our production environment. In order to archieve this, we will be using the actions “allow” and “deny” as well as the audit setting “true”. Because the RPC Firewall protection interacts with the LSASS process on the server it is deployed on, we first have to identify if LSA Protection is enabled in order to decide if our rule set will be based on RPC filters or the RPC firewall rules. The parameter “sid” is one of the Microsoft built-in security identifiers, which can be be found in an overview under the following URL: https://learn.microsoft.com/en-us/windows/win32/secauthz/sid-strings As “BA” should not be allowed in order to prevent local administrators from using DCSync on the target and “SY” should be allowed in order to allow the local system or machine account to call the RPC endpoint successfully. In order to allow the DCSync from domain controllers and audit the calls we will set the two following rules:",
    "html_url": "https://blog.nviso.eu/2023/12/08/rpc-or-not-here-we-log-preventing-exploitation-and-abuse-with-rpc-firewall/",
    "text": "This entry is part 1 in the series RPC Firewall\n\nWelcome, readers, to the first installment of our blog series “Preventing Exploitation and Abuse with the RPC Firewall”.\nIn this post, we’ll delve into how to create rules for the RPC firewall and how to deploy them onto our servers.\nIn the year 2024, we’ll release the second part of this series, where we’ll explore detection possibilities by analyzing the generated Windows events to further enhance your security posture.\n\nIntroduction\n\nRemote Procedure Call (RPC) plays an important role in Windows environments today. RPC is a fundamental mechanism that enables communication between processes, allowing them to request services from one another across a network. In Windows, RPC is utilized extensively for various system functions, such as file and printer sharing, Active Directory authentication, and remote management. However, the widespread use of RPC also makes it an attractive target for attackers.\n\nIntroduction\nWhy should we care?\nWhat can the RPC Firewall do for me?\nRemote RPC Attacks – Detection\nRemote RPC Attacks – Prevention\nComponents of the RPC Firewall\nCreate an RPC Filter/Firewall rule\nIdentify UUID and Operation number of an RPC call\nIdentifying allowed endpoints\nIdentifying possible actions\nChecking the current status of the Local Security Authority (LSA) Protection\nCheck by using the registry\nRule creation with LSA Protection enabled (RPC filters)\nRule creation with LSA Protection disabled (Firewall)\nDeployment\nReferences\nSteffen Rogge\nWhy should we care?\n\nBy exploiting vulnerabilities in RPC implementations, malicious actors can gain unauthorized access, execute arbitrary code, and compromise the security and integrity of a Windows environment. Thus, it is of paramount importance to implement robust security measures to protect against RPC-based attacks, ensuring the confidentiality, availability, and integrity of critical systems and data.\n\nShoutout to the Zero Networks research team, who built a tool called “RPC Firewall“, a free and open source tool that allows the prevention and auditing of RPC calls.\n\nWhat can the RPC Firewall do for me?\nRemote RPC Attacks – Detection\n\nWhen the RPC firewall configuration is configured to audit, RPC events are written to the Windows Event Log and allow for a forward to a central detection and analysis platform.\n\nThe created event entries can then be forwarded to the SIEM and used to create baselines of remote RPC traffic for various servers in the environment.\n\nOnce an abnormal RPC call is audited it can be used to trigger an alert for your SOC/CSIRT team for analysis.\n\nRPC Firewall log entries can be found inside the Windows Event Viewer path “Application/RPCFW”.\nRPC Filter events can be found inside the Windows Security log with the event ID 5712.\n\nRemote RPC Attacks – Prevention\n\nBesides logging, the RPC Firewall can be configured to block potentially malicious RPC calls.\n\nAll other RPC calls are not audited to reduce noise, save storage space and keep the performance impact minimal.\n\nOnce a potentially malicious RPC call is detected, it is blocked and audited/logged which can then be used to alert your SOC/CSIRT team, while keeping the servers protected.\n\nComponents of the RPC Firewall\n\nThe RPC Firewall has 3 main components:\n\nThe rpcFwManager.exe is the main executable that is being used by the RPC Firewall service in the deployment but is also used to reload the changed configuration.\n\nThe file rpcFireWall.dll is injected into the processes in order to allow auditing and filtering of the RPC calls.\n\nThe file rpcMessages.dll is a common library file used for logic that is shared between the other components and responsible for creating and writing the events to the Windows Event log.\n\nThe file RpcFw.conf is the configuration file containing our defined ruleset that will be used to protect and log legitimate use of RPC endpoints.\n\nCreate an RPC Filter/Firewall rule\n\nAlthough the provided rules have been tested in our lab environment, we highly recommend to test the firewall rules in a test or pre-production environment before deploying them into a production network!\n\nIn order to create an RPC firewall rule (Firewall or Filter) we have to complete the following steps:\n\nIdentify the UUID of the RPC call we want to allow/block/audit\nIdentify the operation number (Opnum) of the method\nCollect possible whitelisted IPs of endpoints that should be allowed to access the RPC methods\nDecide if we want to block/allow and/or audit the call\nIdentify UUID and Operation number of an RPC call\n\nFor this example we are going to look at how the script “secretsdump.py” from the impacket toolkit executes the DCSync attack in order to create a rule that prevents it.\n\nIf we take a look at the script here:\n\nhttps://github.com/fortra/impacket/blob/master/impacket/examples/secretsdump.py#L571\n\nWe can identify the method used by analyzing the following lines:\n\n570\n571\n572\n573\n574\n575\n576\n577\n\t\n[...]\n    def _DRSGetNCChanges(self, userEntry, dsName):\n        if self.__drsr is None:\n            self.__connectDrds()\n \n        LOG.debug('Calling DRSGetNCChanges for %s ' % userEntry)\n        request = drsuapi.DRSGetNCChanges()\n[...]\n\nWhich means that impacket is using the RPC method “IDL_DRSGetNCChanges”, which is documented by Microsoft here:\n\nhttps://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-drsr/b63730ac-614c-431c-9501-28d6aca91894\n\nAccording to the Microsoft Documentation, “the IDL_DRSGetNCChanges method replicates updates from an NC replica on the server”.\n\nAs the following sidebar shows, it is part of the RPC interface called “drsuapi”.\n\nIn order to create a rule we do need the UUID for the affected interface and we can find that information here:\n\nParameter\tValue\tReference\nRPC interface UUID for drsuapi methods\te3514235-4b06-11d1-ab04-00c04fc2dcd2\tSection 4.1.1 – section 4.1.29\n…\t…\t…\nhttps://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-drsr/063618ed-b2e2-4983-ab13-3ed056700641\n\nThis gives us the needed UUID for the RPC interface.\n\nYou might have noticed the operation number in the screenshot above and that is indeed what we are looking for and thus we do already have the operation number “3” for our rule.\n\nDRSGetNCChanges -> 4.1.10 IDL_DRSGetNCChanges (Opnum 3)\nIdentifying allowed endpoints\n\nWe are now missing the IP addresses for which the DCSync actions should be allowed and/or audited.\n\nIn a general environment, DCSync is a part of the Active Directory replication process, and it allows a domain controller to request and pull the latest information about user accounts, security groups, and other objects from another domain controller. This synchronization is crucial for maintaining consistency and ensuring that all domain controllers have up-to-date information.\n\nThis also means that we do not want our RPC firewall to block legitimate RPC calls and thus prevent the DCSync and cause problems in our production environment.\n\nFor this example, let’s go with the following environment where we do have 2 domain controllers:\n\nDC1.ecorp.local (IP: 10.0.31.5)\nDC2.ecorp.local (IP: 10.0.31.6)\n\nThis post assumes that, as part of the network configuration, the domain controllers are assigned a static IP address. If your network depends on domain controllers retrieving their IP addresses from a pool, the rule will not automatically update and thus block the DCSync actions sooner or later.\n\nIdentifying possible actions\n\nIn order to correctly configure the rules, we need to define what our use case of the RPC firewall will be. In this example we want:\n\nDomain controllers to be able to synchronize with each other\nBlocking of all other access to DCSync operations on the RPC endpoint\nLogging of attempts to DCSync in order to detect malicious use or possible configuration problems\n\nIn order to archieve this, we will be using the actions “allow” and “deny” as well as the audit setting “true”.\n\nChecking the current status of the Local Security Authority (LSA) Protection\n\nBecause the RPC Firewall protection interacts with the LSASS process on the server it is deployed on, we first have to identify if LSA Protection is enabled in order to decide if our rule set will be based on RPC filters or the RPC firewall rules.\n\nThe current status of the LSA Protection can be checked by using the registry or checking for a group policy that was created in order to set these values.\nFor more information please check the official Microsoft page: https://learn.microsoft.com/en-us/windows-server/security/credentials-protection-and-management/configuring-additional-lsa-protection#enable-lsa-protection-by-using-group-policy\n\nCheck by using the registry\nOpen the Registry Editor RegEdit.exe, and navigate to the registry key HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Lsa.\nCheck the value of the registry key:\n“RunAsPPL”=dword:00000000 = Disabled\n“RunAsPPL”=dword:00000001 = Enabled with a UEFI variable\n“RunAsPPL”=dword:00000002 = Enabled without a UEFI variable (only enforced on Windows 11 build 22H2 and higher)\nRule creation with LSA Protection enabled (RPC filters)\n\nBecause LSA Protection is enabled, the DLL cannot be injected into the LSASS process and thus the RPC firewall does not apply to operations happening inside the application space of the LSASS process. This means we can only rely on RPC filters.\n\nBecause of this restriction we will be working only with RPC filters. Which limitations this might have can be accessed here: https://github.com/zeronetworks/rpcfirewall#using-rpc-firewall-or-rpc-filters\n\nFor the RPC filters we will be making use of the additional parameters “prot” and “sid” in order to fine tune our rule set as the parameter “opnum” is not available when using the RPC filters.\n\nThe parameter “prot” specifies the protocol sequence the rule should match for.\n\nIn our example, we will be using “Connection-oriented named pipes” and this means a value of “ncacn_np” for the parameter “prot”.\n\nConstant/value\tDescription\n…\t…\nncacn_np Connection-oriented named pipes\tClient only: MS-DOS, Windows 3.x, Windows 95 Client and Server: Windows Server 2003, Windows XP, Windows 2000, Windows NT\n…\t…\nhttps://learn.microsoft.com/en-us/windows/win32/rpc/protocol-sequence-constants\n\nThe parameter “sid” is one of the Microsoft built-in security identifiers, which can be be found in an overview under the following URL: https://learn.microsoft.com/en-us/windows/win32/secauthz/sid-strings\n\nIn our example we will be using:\n\nSDDL SID string\tConstant in Sddl.h\tAccount alias and corresponding RID\n“BA“\tSDDL_BUILTIN_ADMINISTRATORS\tBuilt-in administrators. The corresponding RID is DOMAIN_ALIAS_RID_ADMINS.\n…\t…\t…\n“SY“\tSDDL_LOCAL_SYSTEM\tLocal system. The corresponding RID is SECURITY_LOCAL_SYSTEM_RID.\n…\t…\t…\n\nAs “BA” should not be allowed in order to prevent local administrators from using DCSync on the target and “SY” should be allowed in order to allow the local system or machine account to call the RPC endpoint successfully.\n\nBy using the information prepared in the previous steps and our requirements the DCSync can be allowed from both the domain controllers using the following rules:\n\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 prot:ncacn_np sid:BA addr:10.0.31.5 action:allow audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 prot:ncacn_np sid:BA addr:10.0.31.6 action:allow audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 sid:SY action:allow audit:true\n\nBecause we want to block local administrators from being able to DCSync even with the correct permissions and log any tries to do so, we add the following rule:\n\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 sid:BA action:block audit:true\n\nAs we cannot make use of the operation number and just block one specific operation, we decided to allow but audit all further requests to the RPC endpoint. This can be reflected in the following rule:\n\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 action:allow audit:true\n\nThis results in the following final RPC filter rule set for the file “RpcFw.conf”:\n\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 prot:ncacn_np sid:BA addr:10.0.31.5 action:allow audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 prot:ncacn_np sid:BA addr:10.0.31.6 action:allow audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 sid:SY action:allow audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 sid:BA action:block audit:true\nflt:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 action:allow audit:true\nRule creation with LSA Protection disabled (Firewall)\n\nIn order to allow the DCSync from domain controllers and audit the calls we will set the two following rules:\n\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 addr:10.0.31.5 opnum:3 action:allow audit:true\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 addr:10.0.31.6 opnum:3 action:allow audit:true\n\nAs our requirement was that we want to block all other access to DCSync operations on the RPC endpoint and we also wanted to log attempts to DCSync in order to detect malicious use or possible configuration problems, we will be adding this additional rule:\n\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 opnum:3 action:block audit:true\n\nThis results in the final rule set for the configuration file “RpcFw.conf” being:\n\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 addr:10.0.31.5 opnum:3 action:allow audit:true\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 addr:10.0.31.6 opnum:3 action:allow audit:true\nfw:uuid:e3514235-4b06-11d1-ab04-00c04fc2dcd2 opnum:3 action:block audit:true\n\nCreate the Configuration file “RpcFw.conf” in the same directory as the executable “RpcFwManager.exe” and insert your rules in there.\nWhenever the configuration changes, you need to notify the rpcFirewall.dll via the update command: RpcFwManager.exe /update\n\nDeployment\n\nThe following YouTube tutorial provided by the developers of the RPC firewall provides some insights in how to install the software:\n\nReferences\n\nhttps://github.com/zeronetworks/rpcfirewall\n\nStopping Lateral Movement via the RPC Firewall\nSteffen Rogge\n\nSteffen is a Cyber Security Consultant at NVISO, where he mostly conducts Purple & Red Team assessments with a special focus on TIBER engagements.\n\nThis enables companies to evaluate their existing defenses against emulated Advanced Persistent Threat (APT) campaigns.\n\nLinkedIn\nShare this:\nTwitterRedditWhatsAppEmail\nLike this:\nLoading...",
    "title": "RPC or Not, Here We Log: Preventing Exploitation and Abuse with RPC Firewall"
}
{
    "brief": "In this blog post we will take a look at the health monitoring capabilities for log ingestion in Microsoft Sentinel. The log collection is done via the Azure Monitor Agent (AMA) or the Log Analytics Agent (MMA). Microsoft provides two out-of-the-box features to perform health monitoring on the data connectors: The Data connectors health monitoring workbook & SentinelHealth data table. Using the Data connectors health monitoring workbook The Data collection health monitoring workbook is an out-of-the-box solution that provides insight regarding the log ingestion status, detection of anomalies and the health status of the Log Analytics agents. SampleInterval: Define the time interval in which data is sampled in the defined time range. Each time sample gets an anomaly score, which is used for the detection. The SentinelHealth data table For the data connectors, there are two types of events: Data fetch status change & Data fetch failure summary. The Data fetch status change events contain the status of the data fetching and additional information. These events will be logged once an hour if the status is stable (i.e. status doesn’t change from Success to Failure and vice versa). For the first example, we’ll setup an alert in the Log Analytics workspace where Sentinel is running on. The alert logic will run on a recurring basis and alert the necessary people when it is triggered. For starters, we’ll go the the Log Analytics Workspace and and start the creation of a new alert. Select Custom log search for the signal and we’ll use the Connector status change from Success to Failure query example as logic. For the second example, we’ll create a Logic App that will send an overview via Teams of all the tables with an anomalous score. The query is based on the logic from the Data Connector Workbook. The combination of the two out-of-the-box solutions and the flexibility to create custom monitoring solutions, makes Microsoft Sentinel a comprehensive and adaptable choice for managing and monitoring security events.",
    "html_url": "https://blog.nviso.eu/2023/12/06/data-connector-health-monitoring-on-microsoft-sentinel/",
    "text": "Introduction\n\nSecurity information and event management (SIEM) tooling allows security teams to collect and analyse logs from a wide variety of sources. In turn this is used to detect and handle incidents. Evidently it is important to ensure that the log ingestion is complete and uninterrupted. Luckily SIEMs offer out-of-the-box solutions and/or capabilities to create custom health monitoring. In this blog post we will take a look at the health monitoring capabilities for log ingestion in Microsoft Sentinel.\n\nMicrosoft Sentinel\n\nMicrosoft Sentinel is the cloud-native Security information and event management (SIEM) and Security orchestration, automation, and response (SOAR) solution provided by Microsoft. It provides intelligent security analytics and threat intelligence across the enterprise, offering a single solution for alert detection, threat visibility, proactive hunting, and threat response. As a cloud-native solution, it can easily scale to accommodate the growing security needs of an organization and alleviate the cost of maintaining your own infrastructure.\n\nMicrosoft Sentinel utilizes Data Connectors to handle log ingestion. Microsoft Sentinel comes with out of the box connectors for Microsoft services, these are the service-to-service connectors. Additionally, there are many built-in connectors for third-party services, which utilize Syslog, Common Event Format (CEF) or REST APIs to connect the data sources to Microsoft Sentinel.\n\nBesides logs from Microsoft services and third-party services, Sentinel can also collect logs from Azure VMs and non-Azure VMs. The log collection is done via the Azure Monitor Agent (AMA) or the Log Analytics Agent (MMA). As a brief aside, it’s important to note that the Log Analytics Agent is on a deprecation path and won’t be supported after August 31, 2024.\n\nThe state of the Data Connectors can be monitored with the out-of-the-box solutions or by creating a custom solution.\n\nMicrosoft provides two out-of-the-box features to perform health monitoring on the data connectors: The Data connectors health monitoring workbook & SentinelHealth data table.\n\nUsing the Data connectors health monitoring workbook\n\nThe Data collection health monitoring workbook is an out-of-the-box solution that provides insight regarding the log ingestion status, detection of anomalies and the health status of the Log Analytics agents.\n\nThe workbook consists of three tabs: Overview, Data collection anomalies & Agents info.\n\nThe Overview tab shows the general status of the log ingestions in the selected workspace. It contains data such as the Events per Second (EPS), data volume and time of the last log received. For the tab to function, the required Subscription and Workspace have to be selected at the top\n\n\nThe Data collection anomalies tab provides info for detecting anomalies in the log ingestion process. Each tab in the view presents a specific table. The General tab is a collection of a multiple tables.\n\nWe’re given a few configuration options for the view:\n\nAnomaliesTimeRange: Define the total time range for the anomaly detection.\nSampleInterval: Define the time interval in which data is sampled in the defined time range. Each time sample gets an anomaly score, which is used for the detection.\nPositiveAlertThreshold: Define the positive anomaly score threshold.\nNegativeAlertThreshold: Define the negative anomaly score threshold.\n\nThe view itself contains the expected amount of events, the actual amount of events & anomaly score per table. When a significant drop or rise in events is detected, a further investigation is advised. The logic behind the view can also be re-used to setup alerting when a certain threshold is exceeded.\n\nThe Agent info tab contains information about the health of the AMA and MMA agents installed on your Azure and non-Azure machines. The view allows you to monitor System location, Heartbeat status and latency, Available memory and disk space & Agent operations. There are two tabs in the view to choose between Azure machines only and all machines.\n\nYou can find the workbook under Microsoft Sentinel > Workbooks > Templates, then type Data collection health monitoring in the search field. Click View Template to open the workbook. If you plan on using the workbook frequently, hit the Save button so it shows up under My Workbooks.\n\nThe SentinelHealth data table\n\nThe SentinelHealth data table provides information on the health of your Sentinel resources. The content of the table is not limited to only the data connectors, but also the health of your automation rules, playbooks and analytic rules. Given the scope of this blog post, we will focus solely on the data connector events.\n\nCurrently the table has support for following data connectors:\n\nAmazon Web Services (CloudTrail and S3)\nDynamics 365\nOffice 365\nMicrosoft Defender for Endpoint\nThreat Intelligence – TAXII\nThreat Intelligence Platforms\n\nFor the data connectors, there are two types of events: Data fetch status change & Data fetch failure summary.\n\nThe Data fetch status change events contain the status of the data fetching and additional information. The status is represented by Success or Failure and depending on the status, different additional information is given in the ExtendedProperties field:\n\nFor a Success, the field will contain the destination of the logs.\nFor a Failure, the field will contain an error message describing the failure. The content of this message depends on the failure type.\n\nThese events will be logged once an hour if the status is stable (i.e. status doesn’t change from Success to Failure and vice versa). Once a status change is detected it will be logged immediately.\n\nThe Data fetch failure summary events are logged once an hour, per connector, per workspace, with an aggregated failure summary. They are only logged when the connector has experienced polling errors during the given hour. The event itself contains additional information in the ExtendedProperties field, such as all the encountered failures and the time period for which the connector’s source platform was queried.\n\nUsing the SentinelHealth data table\n\nBefore we can start using the SentinelHealth table, we first have to enable it. Go to Microsoft Sentinel > Settings > Settings tab > Auditing and health monitoring, press Enable to enable the health monitoring.\n\nOnce the SentinelHealth table contains data, we can start querying on it. Below you’ll find some example queries to run.\n\nList the latest failure per connector\n\nSentinelHealth\n| where TimeGenerated > ago(7d)\n| where OperationName == \"Data fetch status change\"\n| where Status == \"Failure\"\n| summarize TimeGenerated = arg_max(TimeGenerated,*) by SentinelResourceName, SentinelResourceId\n\nConnector status change from Failure to Success\n\nlet success_status = SentinelHealth\n| where TimeGenerated > ago(1d)\n| where OperationName == \"Data fetch status change\"\n| where Status == \"Success\"\n| summarize TimeGenerated = arg_max(TimeGenerated,*) by SentinelResourceName, SentinelResourceId;\nlet failure_status = SentinelHealth\n| where TimeGenerated > ago(1d)\n| where OperationName == \"Data fetch status change\"\n| where Status == \"Failure\"\n| summarize TimeGenerated = arg_max(TimeGenerated,*) by SentinelResourceName, SentinelResourceId;\nsuccess_status\n| join kind=inner (failure_status) on SentinelResourceName, SentinelResourceId\n| where TimeGenerated > TimeGenerated1\n\nConnector status change from Success to Failure\n\nlet success_status = SentinelHealth\n| where TimeGenerated > ago(1d)\n| where OperationName == \"Data fetch status change\"\n| where Status == \"Success\"\n| summarize TimeGenerated = arg_max(TimeGenerated,*) by SentinelResourceName, SentinelResourceId;\nlet failure_status = SentinelHealth\n| where TimeGenerated > ago(1d)\n| where OperationName == \"Data fetch status change\"\n| where Status == \"Failure\"\n| summarize TimeGenerated = arg_max(TimeGenerated,*) by SentinelResourceName, SentinelResourceId;\nsuccess_status\n| join kind=inner (failure_status) on SentinelResourceName, SentinelResourceId\n| where TimeGenerated > TimeGenerated1\n\nCustom Solutions\n\nWith the help of built-in Azure features and KQL queries, there is the possibility to create custom solutions. The idea is to create a KQL query and then have it executed by an Azure feature, such as Azure Monitor, Azure Logic Apps or as a Sentinel Analytics Rule. Below you’ll find two examples of custom solutions.\n\nLog Analytics Alert\n\nFor the first example, we’ll setup an alert in the Log Analytics workspace where Sentinel is running on. The alert logic will run on a recurring basis and alert the necessary people when it is triggered. For starters, we’ll go the the Log Analytics Workspace and and start the creation of a new alert.\n\nSelect Custom log search for the signal and we’ll use the Connector status change from Success to Failure query example as logic.\n\nSet both the aggregation and evaluation period to 1hr, so it doesn’t incur a high monthly cost. Next, attach an email Action Group to the alert, so the necessary people are informed of the failure.\n\nLastly, give the alert a severity level, name and description to finish off.\n\nLogic App Teams Notification\n\nFor the second example, we’ll create a Logic App that will send an overview via Teams of all the tables with an anomalous score.\n\nFor starters, we’ll create a logic app and create a Workflow inside the logic app.\n\nInside the Workflow, we’ll design the logic for the Teams Notification. We’ll start off with a Recurrence trigger. Define an interval on which you’d like to receive notifications. In the example, an interval of two days was chosen.\n\nNext, we’ll add the Run query and visualize results action. In this action, we have to define the Subscription, Resource Group, Resource Type, Resource Name, Query, Time Range and Chart Type. Define the first parameters to select your Log Analytics Workspace and then use following query. The query is based on the logic from the Data Connector Workbook. The query looks back on the data of the past two weeks with an interval of one day per data sample. If needed, the time period and interval can be increased or decreased. The UpperThreshold and LowerThreshold parameter can be adapted to make the detection more or less sensitive.\n\nlet UpperThreshold = 5.0; // Upper Anomaly threshold score\nlet LowerThreshold = -5.0; // Lower anomaly threshold score\nlet TableIgnoreList = dynamic(['SecurityAlert', 'BehaviorAnalytics', 'SecurityBaseline', 'ProtectionStatus']); // select tables you want to EXCLUDE from the results\nunion withsource=TableName1 *\n| make-series count() on TimeGenerated from ago(14d) to now() step 1d by TableName1\n| extend (anomalies, score, baseline) = series_decompose_anomalies(count_, 1.5, 7, 'linefit', 1, 'ctukey', 0.01)\n| where anomalies[-1] == 1 or anomalies[-1] == -1\n| extend Score = score[-1]\n| where Score >= UpperThreshold or Score <= LowerThreshold\n| where TableName1 !in (TableIgnoreList)\n| project TableName=TableName1, ExpectedCount=round(todouble(baseline[-1]),1), ActualCount=round(todouble(count_[-1]),1), AnomalyScore = round(todouble(score[-1]),1)\n\nLastly, define the Time Range and Chart Type parameter. For Time Range pick Set in query and for Chart Type pick Html Table.\n\nNow that the execution of the query is defined, we can define the sending of a Teams message. Select the Post message in a chat or channel action and configure the action to send the body of the query to a channel/person as Flowbot.\n\nOnce the Teams action is defined, the logic app is completed. When the logic app runs, you should expect an output similar to the image below. The parameters in the table can be analysed to detect Data Connector issues.\n\nConclusion\n\nIn conclusion, as stated in the intro, monitoring the health of data connectors is a critical part of ensuring an uninterrupted log ingestion process into the SIEM. Microsoft Sentinel offers great capabilities for monitoring the health of data connectors, thus enabling security teams to ensure the smooth functioning of log ingestion processes and promptly address any issues that may arise. The combination of the two out-of-the-box solutions and the flexibility to create custom monitoring solutions, makes Microsoft Sentinel a comprehensive and adaptable choice for managing and monitoring security events.\n\nFrederik Meutermans\n\nFrederik is a Senior Security Consultant in the Cloud Security Team. He specializes in the Microsoft Azure cloud stack, with a special focus on cloud security monitoring. He mainly has experience as security analyst and security monitoring engineer.\n\nYou can find Frederik on LinkedIn.\n\nLinkedIn\nShare this:\nTwitterRedditWhatsAppEmail\nLike this:\nLoading...",
    "title": "Data Connector Health Monitoring on Microsoft Sentinel"
}
{
    "brief": "But in the history of competitive endeavours nobody has won by playing defence alone. We have this idea that we can wrap our users and systems in enough padding to protect them in a world where guns exist. We’ve leaned so hard into this idea that we’re on the floor and it’s time to look up.",
    "html_url": "https://sensepost.com/blog/2023/why-defend-harder-wont-work-in-the-long-run-and-what-to-do-instead-arrest-criminals/",
    "text": "The whole of information/cyber security is founded on the idea that we can defend ourselves into security. But in the history of competitive endeavours nobody has won by playing defence alone. We have this idea that we can wrap our users and systems in enough padding to protect them in a world where guns exist. We’ve leaned so hard into this idea that we’re on the floor and it’s time to look up. \n\nIn a recent keynote at BSides Cape Town I explored this idea and tried to convince people both that defending harder is an idea with a diminishing ROI, and that we instead need to use law enforcement to impact the problem at its root cause – the criminals. Most in infosec believe and operate as if this is neither their job nor a worthwhile pursuit. I want to change that. First by convincing you that it’s worthwhile, then by helping us understand how we can orient our activities to better invoke law enforcement. \n\nI’d love you to watch the talk and let me know what you think. Because it’s an idea that needs experimentation and practise. Can you include some of this in your strategy for next year?\n\nWatch on YouTube",
    "title": "Why defend harder won’t work in the long run and what to do instead – arrest criminals"
}
{
    "brief": "That is, giving back more than you take. And by giving back I don’t mean *just* doing research or writing tools. In my talk, “your contributions, today” I reflected on a current view of practical security research and contributions in a time of ever-increasing systems complexity, abstractions and Instagram reels.",
    "html_url": "https://sensepost.com/blog/2023/your-contributions-today/",
    "text": "Keynoting 0xcon in Johannesburg this year, I had the immense privilege of talking and sharing ideas about something that is dear to my heart. That is, giving back more than you take. And by giving back I don’t mean *just* doing research or writing tools. Instead, giving back includes things like writing documentation or even just teaching someone else!\n\nIn my talk, “your contributions, today” I reflected on a current view of practical security research and contributions in a time of ever-increasing systems complexity, abstractions and Instagram reels. By drawing parallels to the “Free-rider Problem” as described in an economics context, I argued that as an industry we need to caution against this phenomenon manifesting by actively making contributions.\n\nThe talk is available to view on YouTube now, and you can get the slides from my GitHub repository. What are you going to contribute today?",
    "title": "your contributions, today"
}
{
    "brief": "In CrowdStrike, this is called Real Time Response, and it provides a wide range of capabilities, from executing built-in commands like ipconfig and netstat to running your own PowerShell scripts. I’ll also be providing the code for the threat hunting script, and by the end of this blog you will be able to use the script to pull registry run keys, scheduled tasks, WMI subscriptions, startup folder files, and services from multiple machines, to uncover hidden persistence mechanisms. Before interacting with CrowdStrike’s Oauth2 API via PSFalcon, you will need PowerShell installed and a valid API client (which consists of a ClientID and a secret), that you can create via this link https://falcon.crowdstrike.com/api-clients-and-keys/clients. runscript: To run a PowerShell script Arguments: the Base64 commands about to be executed Timeout: timeout limit Group_ID: The ID of the host group With that done, you are ready to run it via the command line. In this blog post, we looked into how the PSFalcon module can be leveraged in order to execute multiple commands in a group of hosts in CrowdStrike for threat hunting purposes. Identify persistence via registry run keys in a host with a crypto miner infection, which was not detected by the CrowdStrike agent since it was a pre-sensor malware infection and the host had not been rebooted in order for a detection to have triggered. All in all, this code and the methodology presented could be modified to execute any PowerShell command in a group of hosts, so feel free to experiment with your own commands, whether it is threat hunting, system hardening or whatever else you want to do.",
    "html_url": "https://blog.nviso.eu/2023/12/13/scaling-your-threat-hunting-operations-with-crowdstrike-and-psfalcon/",
    "text": "Introduction\n\nMost modern day EDRs have some sort of feature which allows blue teamers to remotely connect to hosts with an EDR agent/sensor installed, to aid in their investigation of incidents. In CrowdStrike, this is called Real Time Response, and it provides a wide range of capabilities, from executing built-in commands like ipconfig and netstat to running your own PowerShell scripts.\n\nIn this blog post, I’ll showcase how CrowdStrike’s PSFalcon PowerShell module can be used to execute RTR commands on multiple hosts at once for the purpose of threat hunting. I’ll also be providing the code for the threat hunting script, and by the end of this blog you will be able to use the script to pull registry run keys, scheduled tasks, WMI subscriptions, startup folder files, and services from multiple machines, to uncover hidden persistence mechanisms. Attackers may establish persistence in your environment without being detected, as such hunting for some of the techniques they use could uncover a potential breach. You can find the Persistence-Hunter script here: https://github.com/NVISOsecurity/blogposts/blob/master/Persistence%20Hunter/Persistence-Hunter.ps1\n\nGetting started\n\nBefore interacting with CrowdStrike’s Oauth2 API via PSFalcon, you will need PowerShell installed and a valid API client (which consists of a ClientID and a secret), that you can create via this link https://falcon.crowdstrike.com/api-clients-and-keys/clients. You can get an API client yourself if you have the Falcon administrator role, otherwise an administrator has to provide you with one. Make sure that your client has the Real time response (admin): Write permission enabled. After your API client is created, you have to install the PSFalcon module. You can find instructions on that through this link https://github.com/CrowdStrike/psfalcon/wiki/Installation,-Upgrade-and-Removal#use-the-powershell-gallery. Once that is done, run Show-FalconModule in a PowerShell prompt to verify that everything is correctly installed.\n\nSince API keys could provide someone with a great deal of access, here are some best practices to keep in mind when handling them:\n\nPrinciple of least privilege; Don’t over assign privileges and rights to your key that are not necessary for the work you will be doing.\nKeep your key (ClientID and secret) stored somewhere safe, preferably a password manager.\nDon’t hardcode your key in a script, for obvious reasons.\nDon’t share your key with anyone, treat it as you would treat a password.\nWorkflow and script details\n\nPersistence-Hunter.ps1 utilizes the PSFalcon module in order to query multiple hosts at once. It initiates Real Time Response sessions to each host in a specific group simultaneously and checks for persistence mechanisms that indicate if a host might be compromised or not.\n\nInvoke-FalconRtr is used to initiates RTR sessions. Depending on the parameter provided, it will start a Real-time Response session with:\n\n-GroupId: Members of the specified host group identifier\n-HostId: A single host identifier\n-HostIds: An array containing one or more host identifiers\n\nExample command:\n\nInvoke-FalconRtr -Command 'runscript' -Argument $Arguments -Timeout 60 -GroupId $group_ID\n\nIn this case, Invoke-FalconRtr was supplied with the with the following parameters:\n\nrunscript: To run a PowerShell script\nArguments: the Base64 commands about to be executed\nTimeout: timeout limit\nGroup_ID: The ID of the host group\n\nSadly, PSFalcon does not understand host group names, so you need to convert the host group name to the corresponding host group identifier (GroupId).\n\nHow do I go from group name to GroupId?\n\nYou can do it manually via PSFalcon. Let’s say you want to find the GroupId of the following group:\n\nDomain - Workstations\n\nFirst, you need to turn all of the characters into lowercase:\n\n$GroupName = 'Domain - Workstations'.ToLower()\n\nYou can get the value of GroupName in a PowerShell prompt to see if it worked by typing $GroupName:\n\ndomain - workstations\n\nThen you need to use the following PSFalcon cmdlet:\n\n$Id = Get-FalconHostGroup -Filter \"name:'$GroupName'\"\n\nOnce again you can get the value of id in a PowerShell prompt by typing $Id :\n\nk43b…………………..d9120\n\nThe value of id is your GroupId, which is a 32-character long string. The GroupId parameter can then be supplied to the Persistence-Hunter script.\n\nWhat are the commands that get executed via the script?\n1. Registry keys (MITRE T1547.001):\n1\n\t\ngi -path 'Registry::HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Run\\' -ea silentlycontinue | out-string ;\n1\n\t\ngi -path 'Registry::HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\RunOnce\\' -ea SilentlyContinue | out-string;\n1\n\t\ngi -path 'Registry::HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\Explorer\\Run\\' -ea silentlycontinue | out-string;\n2. Scheduled tasks: (MITRE T1053.005):\n1\n\t\nschtasks /query /fo csv /v | convertfrom-csv | select TaskName, 'Task To Run', Author | fl | out-string;                                \n3. Startup folder (MITRE T1547.001):\n1\n\t\ngci -path 'C:\\Users\\*\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\*' -ea silentlycontinue | select fullname,Length,CreationTime,LastWriteTime,LastAccessTime,Mode | fl | out-string;\n1\n\t\ngci -path 'C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\\*' -ea silentlycontinue | select fullname,Length,CreationTime,LastWriteTime,LastAccessTime,Mode | fl | out-string;\n4. WMI (MITRE T1546.003):\n1\n\t\nGet-WmiObject -namespace 'root\\subscription' -class __EventConsumer | fl | out-string\n1\n\t\nGet-WmiObject -namespace 'root\\subscription' -class __EventFilter | fl | out-string\n1\n\t\nGet-WmiObject -namespace 'root\\subscription' -class __FilterToConsumerBinding | fl | out-string\n5. Services (MITRE T1543.003):\n1\n\t\ngwmi win32_service |select name,pathname,state,status,startmode| fl | out-string;\nHow can I modify the commands or run other commands?\n\nThe commands need to be Base64 encoded since they are custom scripts to be executed. If you want to run your own PowerShell commands, you can use the following snippet to Base64 encode them:\n\n1\n2\n\t\n$EncodedScript = [Convert]::ToBase64String(\n        [System.Text.Encoding]::Unicode.GetBytes((Get-Content -Path $Path -Raw)))\nRunning the script\n\nBefore running the script, you’ll need to edit line 39 to include your group ID, and change the group name in line 42 as well. With that done, you are ready to run it via the command line. The script will produce 5 different csv files, one for each technique mentioned above. Happy hunting!\n\nConclusion\n\nIn this blog post, we looked into how the PSFalcon module can be leveraged in order to execute multiple commands in a group of hosts in CrowdStrike for threat hunting purposes.\n\nThis script has assisted me in the following use cases:\n\nIdentify persistence via registry run keys in a host with a crypto miner infection, which was not detected by the CrowdStrike agent since it was a pre-sensor malware infection and the host had not been rebooted in order for a detection to have triggered.\nIdentify plaintext credentials in backup related scheduled tasks, also something that CrowdStrike did not generate an alert on, since it is not malicious per se, but could be abused by attackers.\n\nAll in all, this code and the methodology presented could be modified to execute any PowerShell command in a group of hosts, so feel free to experiment with your own commands, whether it is threat hunting, system hardening or whatever else you want to do.\n\nDimitris Binichakis\n\nDimitris is a senior cybersecurity consultant at NVISO working as a Cyber Emergency Response Team (CERT) member. In his free time, he enjoys tinkering with code and skateboarding.\n\nLinkedIn\n\nShare this:\nTwitterRedditWhatsAppEmail\nLike this:\nLoading...",
    "title": "Scaling your threat hunting operations with CrowdStrike and PSFalcon"
}
