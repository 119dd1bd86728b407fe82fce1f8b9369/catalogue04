# Microsoft Teams Covert Channels Research

https://blog.compass-security.com/2024/01/microsoft-teams-covert-channels-research/
<blockquote>
In this article, four covert channels are discussed, with three dedicated to outgoing and the fourth to incoming traffic. The identified covert channels for outgoing traffic include a webhook, a Teams message, and a Teams call channel. However, for incoming traffic, the article outlines a message covert channel, which is different from any of the outgoing message channel. Outgoing Channel: Webhook In the Microsoft Teams settings, a webhook can be attached to a Teams channel, providing an outside world API to deposit messages in that channel. Figure 2: Incoming Webhook Covert Channel Flowchart On the victim side, a Teams card (JSON) is created including an image reference linking to the attacker’s server (AS), appending data to be exfiltrated (resultquery). The video (Figure 3: Webhook Data Exfiltration Demo) displays a proof-of-concept setup and procedure for how data can be exfiltrated using webhooks. Afterwards, the victim will launch a script that sends Teams cards to the webhook and appends each entry from a list of strings (data to exfiltrate) to an embedded image, which is then ultimately being requested from the attacker server. It might not be obvious at first glance but note that prohibiting webhook creation by Teams configuration will not necessarily stop an attacker from creating their own channel with a malicious webhook and using that one for an attack. However, this would need interception or proxyfication of Teams traffic which is not necessarily supported. The covert channel can be created by encapsulating the data into UDP packets and sending them over to the relay server. The incoming packets are not validated by the server and are thus forwarded to the other user on the call (the attacker). Once the client is successfully authenticated to the relay server, it should be able to send traffic to the server using e.g. UDP. However, to avoid any confusion, the PoC is designed to inject additional packets to an outgoing UDP call (Figure 4) connection which was previously negotiated using the ICE protocol and all traffic is relayed over an Internet server. Unfortunately, the call’s UDP packets and the data to exfiltrate, specifically when data is encrypted before exfiltration, have very similar entropy. This fourth and last covert channel allows for an incoming connection from the attacker to the victim. The channel exploits the message flow in a similar manner as the previous covert channel. To send a Microsoft Teams message through the API on https://amer.ng.msg.teams.microsoft.com, the following JSON structure is needed: It is possible to send HTML instead of text in the “content” field, defining key “messagetype” to “RichText/Html”. The discovery of covert channels within Microsoft Teams introduces new opportunities for extracting information, even in the presence of security policies and strict egress traffic rules. Previous work on covert channels using GIF images has already been conducted by Bobbyr, where he introduces the concept of covert channels in MS Teams.
</blockquote>

---

# Is the Google search bar enough to hack Belgian companies?

https://blog.nviso.eu/2024/01/22/is-the-google-search-bar-enough-to-hack-belgium-companies/
<blockquote>
Below is a short list of vulnerabilities identified during the security research, using only the Google search bar on the web applications of Belgian corporations: The technique Google Dorking is also referred to as Google hacking, which is a method used by security researchers and cybercriminals to exploit the power of the Google search engine to unearth vulnerabilities on the Internet. However, we will not share any of the actual Google dork queries or the methodology behind them that were used to identify vulnerabilities. Therefore, an attacker can easily guess those credentials if not changed and gain access to the management portal. Upon identifying the target software, the attacker can use a combination of Google search operators to refine the search results to only display web applications hosting that specific management portal. A lot of management portal software names are written in the title of the web application which is not a security issue at all. The usage of a single Google dork will, of course, not provide the most refined results to target a specific management portal application. However, the approach is the same; more advanced operators in combination have to be used in order to target very specific management portals. To limit the access of robots and web crawlers to your site, you can add the following robots.txt file to the root directory of the web server hosting the management portal application: The compromise of a web server will not be due to web crawlers indexing the endpoint of a management portal or the presence of a software name within the title tag. The methodology for identifying LFI vulnerabilities using Google dork may not be as straightforward as identifying management portals. It is possible to search specifically for these common parameters, which are used for such purposes. There are several Google search queries that can be used to search for the presence of these parameters in web applications. The following is an example of a Google dork: The above shown Google dork query searches web applications with “file” in their URL. However, as you will notice, these search results will not refine to web applications containing parameters named “file” but will also include directories with the string “file.” During my research, I was able to use a combination of several Google search queries with specific key characters and special characters to refine the search results to web applications only with a “file” parameter in their URL. As explained above, I developed a methodology that refines Google search results to identify web applications hosted in Belgium, which contain the specific parameters I was targeting. Do note that depending on the structure of the web application, it might not be possible to create such Disallow entries, since those parameters are used in functionality that is by design intended to be public and should be included in search results. Test environments are often hosted under a subdomain of the production web applications. With the information obtained above a Google Dork can be defined to search specifically for web servers containing those subdomains within the URL. The remediation steps for test environments are quite straightforward. Sensitive Information Disclosure Description The Google dork can also be utilized to search for specific strings. This functionality can be leveraged to search for sensitive strings or directories to discover potentially sensitive information on web servers. The above search query is used to identify openly accessible directories that include the word ‘app.’ While a directory listing on a web server already presents a security issue, it does not necessarily mean that an attacker will immediately find sensitive information due to this issue. Finally, during the research I found a lot of web servers exposing sensitive information such as, plain-text database credentials, plain-text credentials of login portals, web server configurations and even such issues which cannot be mentioned. The methodology in order to identify XSS vulnerabilities is akin to that used for identifying LFI vulnerabilities though the use of Google dork. Next, refining Google dork queries to target these specific parameters and uncover the web applications for vulnerabilities. Figure 9 – Asking ChatGPT for a Google Dork As previously demonstrated, we obtained a Google search query to search for web servers that meet our specific criteria. For the purposes of the security research, I employed a commonly used XSS payload to demonstrate to the relevant company or organization the presence of such a vulnerability. Last but not least, how much the above scenario is applicable for the organization in question is for me to know and for the audience to find out. In order to prevent cybercriminals to uncover sensitive information or vulnerabilities on your web applications using Google dork, a proactive approach is required to manage your online resources. However, in the case that a developer solely relied on the robots.txt file to hide the sensitive parts of their web application and included those directories and files, this information can act as a roadmap to your sensitive information on your website for attackers. Below is a real-world example of a robots.txt file used by a web server not allowing to index the top-secret directory. However, an attacker can gain valuable information by a publicly available file on the web server. Then, if an attacker can identify a vulnerability such as a LFI I found earlier during this research, without any doubt, it will be the first place to exfiltrate data as a directory called top-secret will most likely contain sensitive information. However, it can serve as a defense-in-depth approach to take a countermeasure for exposing sensitive information on your web server. Nevertheless, it has an impact on the likelihood of the vulnerability. The first factor is what kind of an impact the vulnerability has on the web application in question. From my research, I concluded that there is not a solid one way solution to prevent attackers easily identifying vulnerabilities and exposed sensitive information on your web servers. Secure storage of sensitive data: The web server’s file directory should not store sensitive data such as personal information at all.
</blockquote>

---

